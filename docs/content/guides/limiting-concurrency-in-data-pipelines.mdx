---
title: "Limiting concurrency in data pipelines | Dagster Docs"
description: "TODO"
---

# Limiting concurrency in data pipelines

Concurrency is an essential concept in modern programming, particularly when working with data pipelines. While concurrency can improve the efficiency of your pipelines, too many processes executing at once can cause issues. Limiting concurrency in your data pipelines can help prevent performance problems and downtime.

By the end of this guide, you'll:

- Understand the basics of concurrency
- Learn about the options Dagster offers for limiting concurrency
- Learn how to configure concurrency in Dagster
- Understand how to troubleshoot run queueing issues

---

## Understanding the basics

Concurrency is the ability of a system to execute multiple processes in parallel. Before we go any further, let's go over the terminology in this guide:

- **Op** - The core unit of computation in Dagster, an [op][op-concept] is a function that performs a task — for example, sending an email or kicking off a job in dbt.
- **Asset** - A [**Software-defined Asset**][sda-concept] is a Dagster object that couples an asset to the function and upstream assets used to produce its contents. An **asset** is an object in persistent storage, such as a table, file, or persisted machine learning model.
- **Job** - A [**job**][job-concept] is a graph of ops or assets connected via data dependencies. Jobs are the main unit of execution and monitoring in Dagster.
- **Run** - A **run** refers to a single execution of a job in Dagster.
- **Run queue** - A sequence of Dagster runs waiting to be executed.

### Understanding Dagster’s concurrency limit options

Dagster supports placing limits on the number of processes that can be in progress at a single time, at the run and op-level. Depending on your needs, one or both types may be suitable:

- **Run concurrency** controls the total number of runs in a deployment that can execute at the same time. Run concurrency applies to both op and asset-based jobs and all [code locations][code-location-concept] in a single deployment. Any runs beyond the limit will be queued and won’t use any compute.
- **Op concurrency** controls the number of ops that can execute in parallel in a single run. **Note**: Op-level concurrency is a bit misleading - this type of concurrency applies to both op **and** asset-based jobs.

By controlling the number of parallel processes Dagster executes, you can ensure that resources are not overwhelmed and that each process has the resources it needs to run efficiently. This can lead to faster and more reliable pipeline execution, as well as easier monitoring and debugging of issues.

---

## Configuring run-level concurrency

Run concurrency can be configured by:

- Limiting the overall number of runs in a deployment
- Specifying limits using tags

These methods of limiting concurrency can be used individually or together. For each queued run, Dagster will check that launching the run will satisfy all conditions. For example, if launching a run would exceed the maximum number of concurrent runs, Dagster will queue the run until another run finishes.

<TabGroup>
<TabItem name="Limiting overall runs">

### Limiting overall runs

How you limit the overall number of runs in a deployment depends on whether you're using Dagster Open Source or Dagster Cloud:

- **Dagster Open Source**: Use your instance's `dagster.yaml`
- **Dagster Cloud**: Use the [Dagster Cloud UI or the dagster-cloud CLI][cloud-deployment-settings]

To define a maximum run limit, use `run_queue.max_concurrent_runs`. For example, the following would limit the number of concurrent runs for the deployment to 15:

```yaml file=/deploying/concurrency_limits/dagster.yaml startafter=start_overall_example endbefore=end_overall_example
run_queue:
  max_concurrent_runs: 15
```

When defining a value for `max_concurrent_runs`, keep the following in mind:

- This setting defaults to `10`
- Disable the setting with a `-1` value. **Note:** All other negative numbers are invalid.
- A value of `0` prevents any runs from launching

</TabItem>
<TabItem name="Limiting specific runs using tags">

### Limiting specific runs using tags

How you limit specific runs based on tags depends on whether you're using Dagster Open Source or Dagster Cloud:

- **Dagster Open Source**: Use your instance's `dagster.yaml`
- **Dagster Cloud**: Use the [Dagster Cloud UI or the dagster-cloud CLI][cloud-deployment-settings]

To enable this limit use `run_queue.tag_concurrency_limits`. This key accepts a list of tags and their corresponding concurrency limits.

```yaml file=/deploying/concurrency_limits/dagster.yaml startafter=start_tag_example endbefore=end_tag_example
run_queue:
  max_concurrent_runs: 15
  tag_concurrency_limits:
    - key: "database"
      value: "redshift" # applies when the `database` tag has a value of `redshift`
      limit: 4
    - key: "dagster/backfill" # applies when the `dagster/backfill` tag is present, regardless of value
      limit: 10
```

Let’s review what this configuration will do:

- For runs with a `database` tag with a value of `redshift`, a maximum of four runs can execute concurrently
- For runs with a `dagster/backfill` tag, a maximum of 10 runs can execute concurrently. Note that this implementation applies to **any** value of the `dagster/backfill` tag, whereas the `database: redshift` example only applies the limit when there’s a specific tag value.

#### Limiting runs by unique tag value

To apply separate limits to each unique value of a tag, set a limit for each unique value using `applyLimitPerUniqueValue`:

```yaml file=/deploying/concurrency_limits/dagster.yaml startafter=start_unique_value_example endbefore=end_unique_value_example
run_queue:
  - key: "use-case"
    value:
      applyLimitPerUniqueValue: true
    limit: 3
```

With this configuration, each unique value of the `use-case` tag will be limited to three concurrent runs. For example, `team: marketing` and `team: sales` will both be limited to three concurrent runs each.

</TabItem>
</TabGroup>

---

## Configuring op/asset-level concurrency

<Note>
<strong>Looking for global op/asset concurrency?</strong> Dagster doesn’t currently support global (across multiple runs) op/asset concurrency out-of-the-box. If you require concurrency that applies to all ops/assets in a deployment, check out our <a href="/deployment/guides/celery">integration with Celery</a>.
</Note>

Utilizing op/asset-level concurrency provides fine-grained control for the maximum number of ops/assets that can be executed at once within a single run, ensuring that resources shared by multiple ops/assets aren't overwhelmed.

Op and asset concurrency can be configured by:

- Limiting the number of ops/assets that can execute in a single run at once. This is done by limiting concurrency in a job.
- Specifying limits using tags

### Limiting overall concurrency in a job

To limit concurrency for ops and assets in jobs, use `multiprocess.max_concurrent` in the job’s config. **Note:** While the argument is the same for both op and asset-based jobs, how jobs are defined differs between assets and ops. Click the tabs below for examples.

<TabGroup>
<TabItem name="Asset-based jobs">

#### Asset-based jobs

Asset jobs are defined using `define_asset_job`. In this example, the job will execute up to three assets at once:

```python
assets_job = define_asset_job(
    name="assets_job",
    config={
        "execution": {
            "config": {
                "multiprocess": {
                    "max_concurrent": 3,      # limits concurrent assets to 3
                },
            }
        }
    }
)
```

</TabItem>
<TabItem name="Op-based jobs">

#### Op-based jobs

Op-based jobs are defined using the `@job` decorator. In this example, the job will execute up to four ops at once:

```python
@job(
    config={
        "execution": {
            "config": {
                "multiprocess": {
                    "max_concurrent": 4,      # limits concurrent ops to 4
                },
            }
        }
    }
)
def tag_concurrency_job():
    ...
```
</TabItem>
</TabGroup>


### Limiting concurrency using tags

Limits can be specified for all ops/assets with a specific tag key or key-value pair. If any limit would be exceeded by launching an op/asset, then the op/asset will be queued.

To specify limits on the number of ops/assets with a specific tag, use `tag_concurrency_limits` in the job’s config. **Note:** While the argument is the same for both op and asset-based jobs, how jobs are defined differs between assets and ops. Click the tabs below for examples.

<TabGroup>
<TabItem name="Asset-based jobs">

#### Asset-based jobs

Unlike op-based jobs, asset jobs use the `op_tags` field on each asset when checking them for tag concurrency limits. In this example, the job will execute up to three assets at once with the `database` tag equal to `snowflake`:

```python
# example asset with tags, specified using op_tags
@asset(op_tags={"database": "snowflake"})
def asset1():
    ...

assets_job = define_asset_job(
    name="assets_job",
    config={
        "execution": {
            "config": {
                "multiprocess": {
                    "tag_concurrency_limits": [
                        {
                            "key": "database",
                            "value": "snowflake",
                            "limit": 3,
                        }
                    ],
                },
            }
        }
    }
)
```

</TabItem>
<TabItem name="Op-based jobs">

#### Op-based jobs

In this example, the job will execute up to two ops at once with the `database` tag equal to `redshift`:

```python file=/concepts/ops_jobs_graphs/job_execution.py startafter=start_tag_concurrency endbefore=end_tag_concurrency
@job(
    config={
        "execution": {
            "config": {
                "multiprocess": {
                    "tag_concurrency_limits": [
                        {
                            "key": "database",
                            "value": "redshift",
                            "limit": 2,
                        }
                    ],
                },
            }
        }
    }
)

def tag_concurrency_job():
    ...
```

</TabItem>
</TabGroup>

---

## Troubleshooting

When limiting concurrency, you might run into some issues until you get the configuration right.

| Issue                                               | Description and resolution                                                                      |
| --------------------------------------------------- | ----------------------------------------------------------------------------------------------- |
| Runs skip the QUEUED status and go right to STARTED | Your instance may not be using the QueuedRunCoordinator, which is responsible for run queueing. |

Verify your instance is using the correct run coordinator by navigating to Deployment > Configuration in the Dagster UI. | | Runs remain in the QUEUED status | If runs aren’t being dequeued, the root cause is likely an issue with the Dagster daemon or the queue configuration.

Step 1: Verify the Dagster daemon is set up and running

In the Dagster UI, navigate to Deployment > Daemons and verify that the daemon is running. The Run queue should also be running. If you used dagster dev to start the Dagster UI, the daemon should have been started for you.

If the daemon isn’t running, proceed to step 2.

Step 2: Verify the Dagster daemon can access the same storages as the Dagit process

Both the Dagit (Dagster UI) process and Dagster daemon should access the same storage, meaning they should use the same dagster.yaml. Locally, this means both processes should have the same set DAGSTER_HOME environment variable. Refer to the <https://docs.dagster.io/deployment/dagster-instance> docs for more information.

Check the queue configuration

If the daemon is running, runs may intentionally be left in the queue due to concurrency rules. To investigate, you can:

- Check the output logged from the daemon process, as this will include skipped runs.
- Check the max_concurrent_runs setting in your instance’s dagster.yaml. If set to 0, this may block the queue. You can check this setting in the Dagster UI by navigating to Deployment > Configuration and locating the run_coordinator.config.max_concurrent_runs setting.
- Check the state of your run queue. In some cases, the queue may be blocked by some number of in-progress runs. To view the status of your run queue, click Runs in the top navigation of the Dagster UI and then open the Queued and In Progress tabs. If there are queued or in-progress runs blocking the queue, you can terminate them to allow other runs to proceed. |

---

## Related

- [Customizing run queue priority][custom-run-queue]
- Job execution
- [Software-defined assets][sda-concept]
- [Ops][op-concept]

[op-concept]: /concepts/ops-jobs-graphs/ops

[sda-concept]: /concepts/assets/software-defined-assets

[job-concept]: /concepts/ops-jobs-graphs/jobs

[code-location-concept]: /concepts/code-locations

[custom-run-queue]: /guides/customizing-run-queue-priority

[cloud-deployment-settings]: /dagster-cloud/developing-testing/managing-deployments#configuring-deployment-settings
