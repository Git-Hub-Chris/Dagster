---
title: Building and memoizing versioned assets | Dagster Docs
---

# Building and memoizing versioned assets

Thie guide shows you how to build memoizable graphs of assets. Using this style, one can avoid unnecessary recomputations, speeding up the developer workflow and saving computational resources.

---

# Context

Dagster embraces functional programming principles. The core abstraction is a software-defined asset which, in its idealized form, is a side-effect-free function that produces an asset, with upstream assets as inputs.

Writing programs in a functional style allows one to utilize memoization as a way to save time and resources. If one calls a function twice with identical inputs, you can return the previously computed result rather than do a full recomputation.

In data pipelining, where assets can be expensive to compute, this approach can yield tremendous results. In order for Dagster to provide memoization features on users behalfs, it supports the concept of versioning.

There are two cases when you need to perform recomputation on a pure function:

1. The function has changed
2. The inputs to the function have changed

To support these two cases, Dagster has two concepts of versioning

1. Code versioning. A string that represents the version code behind an asset. This is the `code_version` argument of `@asset`
2. Data versioning. A string that represents the version of the physical asset. This is known as a logical version. (e.g. `LogicalVersion`)

---

## Step One: Understanding Staleness

Dagster automatically computes the logical version of software-defined assets on your behalf. It does this using code versioning and data versioning.

Let's start with a trivial asset that returns a hardcoded number.

```python file=/guides/dagster/building_versioned_assets/vanilla_asset.py
from dagster import asset


@asset
def a_number():
    return 1
```

Now materialize it and look at the entry in the Asset Catalog.

SCREENSHOT

You'll notice a logical version on the materialization. This is the hash dagster has computed on your behalf.

In this case, since there are no inputs, the logical version is the function of the code version only, which is also viewable in the UI. If you materialize it again, you'll notice the code version changed every time.

This is by design. Dagster has no way of knowing if the code has changed, so it must assume that it changes everytime. How do we fix this?

This is where the code_version argument to @asset comes into play. Add a code version argument.

```python file=/guides/dagster/building_versioned_assets/vanilla_asset_with_code_version.py
from dagster import asset


@asset(code_version="v1")
def versioned_number():
    return 1
```

Materialize this asset.

SCREENSHOT

Now the the user-defined code version, "v1", is in the latest materialization, instead of automatically generated hash.

Now let's update the code _and_ inform dagster that the code has changed. Do this by changing the code version argument.

```python file=/guides/dagster/building_versioned_assets/vanilla_asset_with_code_version_v2.py
from dagster import asset


@asset(code_version="v2")
def versioned_number():
    return 11
```

Now reload your definitons.

SCREENSHOT

Note that the asset is now marked as stale. That is because it has not been materialized since the code is changed and, because of the explicit code_version argument, Dagster knows this. (TODO: Add line here describing where to find this reason in the UI) It must be materialized for it to be up to date.

"Materialize stale and missing" is now no longer grey. You can use it to rematerilize.

Note in the asset materialization the code_version is now v2 and the asset is marked as up to date.

---

## Step Two: Staleness with Dependencies

This becomes more powerful and useful when combinined with dependencies. Let's add an asset downstream of our first asset.

```python file=/guides/dagster/building_versioned_assets/dependencies_code_version_only.py
from dagster import asset


@asset(code_version="v2")
def versioned_number():
    return 11


@asset(code_version="v1")
def multipled_number(versioned_number):
    return versioned_number * 2
```

Reload this in dagit and you'll notice that `multipled_number` and it is marked as "Never Materalized". Now click on "Materialize stale and missing" (get in the habit of doing that as the "Materialize" button does not respect versioning) to materialize). Let's materialize it

Note that in the created run, _only_ the step associated with `multipled_number` is run. The system knows that `versioned_number` is up to date and therefore can safely skip that computation.

Now let's update the `versioned_number` asset. Since `multipled_number` depends on `versioned_number`, it must be recomputed as well. Dagster has this built-in.

SCREENSHOT

They are _both_ marked stale. (TODO: sentence about to click on multipled_number to get the provenance). "Materialize stale and missing" to get these assets up to date.

---

## Step Three: In the real world data has to some with somewhere

We've gone through code versioning, but that is not sufficient to make this useful. In the examples so far we are just hardcoding data in code, and using code version for everything. In the real world, data pipelines depend on upstream data outside of that pipeline. You have to start from somewhere.

We need to compute the data version of external data that our pipeline depends on. External data sources in Dagster are modeled by source assets. We build on that concept, by making the source asset _observable_. An observable source asset has a user-defined function that computes a logical version.

### Version One (with non-argument deps)

In this scenario we simulate a common data scenario, where a file is landed by some sort of external process, and then we set up a pipeline to construct a graph of assets using that file as source data.

So first we add the "observable source asset" called `input_number`. The body of that function computes a hash of the file contents. Then we add the source asset as an upstrem dependency of `versioned_number`.

```python file=/guides/dagster/building_versioned_assets/observable_source_asset_path_with_non_argument_deps.py
from hashlib import sha256

from dagster import LogicalVersion, asset, file_relative_path, observable_source_asset


def sha256_digest_from_str(string: str) -> str:
    hash_sig = sha256()
    hash_sig.update(bytearray(string, "utf8"))
    return hash_sig.hexdigest()


FILE_PATH = file_relative_path(__file__, "input_number.txt")


@observable_source_asset
def input_number():
    with open(FILE_PATH) as ff:
        return LogicalVersion(sha256_digest_from_str(ff.read()))


@asset(code_version="v3", non_argument_deps={"input_number"})
def versioned_number():
    with open(FILE_PATH) as ff:
        return int(ff.read())


@asset(code_version="v1")
def multipled_number(versioned_number):
    return versioned_number * 2
```

Now let's see this action. You'll see a new button called "Observe Sources" (ðŸ¤”). When you click it kicks of a run whose sole purpose is observing the sources.

Look at the entry in the asset catalog for this asset:

SCREENSHOT

Note the "logical version" here that you computed.

Now let's see this in action. Materialize all the asset to bring your graph up to date.

Now let's alter the file manually to simulae the external process dropping a new file. Then clicked the observe sources button again. Now everything is stale again. If you look in the entry in the asset catalog there will be a newer asset observation with a different logical version. This is the metadata that drives the staleness calculation.

### Version Two (with i/o managers)

TODO. It hurts. This the code. Writing docs for this is pretty challenging.

```python file=/guides/dagster/building_versioned_assets/observable_source_asset_path_with_io_managers.py
import os
from hashlib import sha256
from typing import Any

from dagster import (
    Definitions,
    InputContext,
    IOManager,
    LogicalVersion,
    OutputContext,
    asset,
    file_relative_path,
    observable_source_asset,
)
from dagster._seven.temp_dir import get_system_temp_directory
from dagster._utils import mkdir_p


# This simulates the I/O manager for our internal data lake
class NumberTextFileIOManager(IOManager):
    def __init__(self, root_dir: str):
        self.root_dir = root_dir

    @staticmethod
    def with_directory(root_dir: str):
        mkdir_p(root_dir)
        return NumberTextFileIOManager(root_dir=root_dir)

    def load_input(self, context: "InputContext") -> int:
        asset_key_str = context.asset_key.to_user_string()

        full_path = os.path.join(self.root_dir, f"{asset_key_str}.txt")
        with open(full_path) as ff:
            return int(ff.read())

    def handle_output(self, context: "OutputContext", obj: int) -> None:
        # without writing a custom input manager and setting the key on if from the asset in
        # this function gets called by the observable source asset
        # dagster._core.errors.DagsterInvariantViolationError:
        # Attempting to access asset_key, but it was not provided when constructing the OutputContext
        # Even when you override the io_manager_key on the source asset, this is still called

        # The other option is to use the default i/o manager for the source asset
        # to that it writes pickled None somewhere and then use a custom i/o
        # manager key for all the other assets. Both are pretty bad.
        if context.op_def.name == "input_number":
            return

        asset_key_str = context.asset_key.to_user_string()

        full_path = os.path.join(self.root_dir, f"{asset_key_str}.txt")
        with open(full_path, "w") as ff:
            ff.write(str(obj))


def sha256_digest_from_str(string: str) -> str:
    hash_sig = sha256()
    hash_sig.update(bytearray(string, "utf8"))
    return hash_sig.hexdigest()


FILE_PATH = file_relative_path(__file__, "input_number.txt")


# knows how to load file that is dropped somewhere by an external process
class ExternalFileInputManager(IOManager):
    def load_input(self, context: "InputContext") -> object:
        with open(FILE_PATH) as ff:
            return int(ff.read())

    def handle_output(self, context: "OutputContext", obj: Any) -> None:
        raise Exception("This should never be called")


# in order to get the right input loading behavior for the downstream assets
# we need to use the external file input manager key here. pretty confusing when
# coming at this fresh
@observable_source_asset(io_manager_key="external_file_input_manager")
def input_number():
    with open(FILE_PATH) as ff:
        return LogicalVersion(sha256_digest_from_str(ff.read()))


@asset(code_version="v3")
def versioned_number(input_number):
    return input_number


@asset(code_version="v1")
def multipled_number(versioned_number):
    return versioned_number * 2


defs = Definitions(
    assets=[input_number, versioned_number, multipled_number],
    resources={
        "io_manager": NumberTextFileIOManager.with_directory(
            os.path.join(get_system_temp_directory(), "versioning_example")
        ),
        "external_file_input_manager": ExternalFileInputManager(),
    },
)
```

---
