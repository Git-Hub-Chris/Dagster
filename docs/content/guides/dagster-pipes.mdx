---
title: Dagster Pipes | Dagster Docs
description: "Dagster Pipes provides a protocol between the orchestration environment (Dagster) and external execution (ex: Databricks) and a toolkit for building implementations of that protocol."
---

# Dagster Pipes

Dagster Pipes is a toolkit for building integrations between Dagster and external execution environments. It standardizes the process of passing parameters, injecting context information, ingesting logs, and collecting metadata all while remaining agnostic to how remote computations are launched in those environments. This enables the separation of orchestration and business logic in the Dagster ecosystem.

It also smooths the process of incorporating pre-existing code, business logic, and execution environments into Dagster. Using Dagster Pipes, you add just a few lines to your code, and it becomes seamlessly invocable by the orchestrator. In turn, you can stream logs and metadata back to Dagster so you can leverage its observability, lineage, cataloging, and debugging capabilities.

---

## Benefits

With Dagster Pipes, you can:

- Incorporate existing code into Dagster without huge refactors
- Onboard stakeholder teams onto Dagster incrementally
- Run code in external environments, and:
  - Easily pass parameters to the code
  - Stream unstructured logs and structured metadata back to Dagster
- Separate orchestration and business logic environments
- Use languages other than Python with Dagster

---

## Limitations

While Dagster Pipes is lightweight and flexible, there are a few limitations to be aware of:

- **Step launchers are incompatible.**
- **I/O managers aren’t currently supported.** If you rely heavily on I/O managers in remote execution, we recommend using step launchers.

---

## How it works

Dagster Pipes provides a protocol between the orchestration environment (Dagster) and external execution (ex: Databricks) and a toolkit for building implementations of that protocol.

Let’s take a look at how Dagster Pipes would work with the following assumptions:

- We have some external code that contains some business logic.
- Our code also calculates the number of records it processes at a given time. We want to send this metadata back to Dagster.
- We have a Dagster asset that:
  - Provides access to asset context data, such as logging, via <PyObject object="AssetExecutionContext" />
  - Passes some parameter, such as a date, to the external code
  - Invokes the external code

Refer to the following diagram and explanation for how Dagster Pipes would accomplish this, step-by-step. **Note:** Depending on the technology you use (ex: Databricks, Docker), this implementation of the protocol may vary. Refer to the [Understanding Dagster Pipes process guide](/guides/dagster-pipes/understanding-dagster-pipes) for more info.

<Image
alt="Diagram explaining the Dagster Pipes process"
src="/images/guides/dagster-pipes/dagster-pipes-process.png"
width={1000}
height={393}
/>

### In the orchestration process (Dagster)

1. The Dagster asset is executed.
2. A connection to the external process, such as Databricks, is established.
3. Dagster sends context info (ex: `partition_key`, `asset_key`, etc.) and any provided parameters to the external process.

### In the external process

1. The external process is invoked.
2. The external process sends information about its execution, and any specified metadata, to Dagster.

After Dagster receives the data from the external process, it’ll be visible in the [Dagster UI](/concepts/webserver/ui).

---

## Usage

Ready to get started with Dagster Pipes? Depending on what your goal is, how you approach using Dagster Pipes will differ:

- **If you’re writing code that's being orchestrated by Dagster**, all you’ll need to do is lightly modify your existing code. Refer to the [Modifying existing code to work with Dagster Pipes](/guides/dagster-pipes/modifying-existing-code-to-work-with-dagster-pipes) guide for more info and examples.
- **If you need to orchestrate code others have written,** you can use our ready-to-go integrations to execute code in your chosen technology:
  - [Databricks](/guides/dagster-pipes/integrating-databricks-with-dagster-pipes)
  - [Docker](/guides/dagster-pipes/integrating-docker-with-dagster-pipes)
  - [Kubernetes](/guides/dagster-pipes/integrating-kubernetes-with-dagster-pipes)
  - [Subprocess](/guides/dagster-pipes/integrating-subprocess-with-dagster-pipes)
- **If you don’t see your integration or you want to fully customize your Pipes experience,** use these in-depth guides to get up to speed:
  - [Understanding the Dagster Pipes process](/guides/dagster-pipes/understanding-dagster-pipes)
  - [Customizing Dagster Pipes protocols](/guides/dagster-pipes/customizing-dagster-pipes-protocols)
