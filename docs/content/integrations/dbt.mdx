---
title: Dagster with dbt
description: Dagster can orchestrate dbt alongside other technologies.
---

## Using dbt with Dagster

Dagster orchestrates dbt alongside _other technologies_, so you can combine dbt with Spark, Python, etc. in a single workflow. Dagster's software-defined asset (SDA) abstractions make it simple to define data assets that depend on specific dbt models, or to define the computation required to compute the sources that your dbt models depend on.

This guide focuses on how to work with `dbt` models through the SDA framework, which we recommend for most use cases. Dagster's SDAs allow you to map multiple

## dbt Models and Software-Defined Assets

A software-defined asset contains an asset key, a set of upstream asset keys, and an operation that is responsible for computing the asset from its upstream dependencies. Models defined in a `dbt` project are conceptually similar to Dagster's software-defined assets.

- The asset key for a dbt model is (by default) the name of the model.
- The upstream dependencies of a dbt model are defined with `ref` or `source` calls within the model's definition.
- The computation required to compute the asset from its upstream dependencies is the SQL within the model's definition.

These similarities make it natural to want to interact with dbt models as SDAs, making it possible to

### Loading dbt models from a dbt project

For smaller dbt projects where compilation time is not a concern, the simplest way to load your dbt assets into Dagster is the following:

```python
from dagster_dbt import load_assets_from_dbt_project

dbt_assets = load_assets_from_dbt_project(
    project_dir="path/to/dbt/project"
)
```

The `load_assets_from_dbt_project` function will compile your dbt project, parse the metadata that dbt provides, and generate a set of software-defined assets that reflect the models in the project. These assets will all share the same underlying operation, which will invoke dbt to run the models represented by the loaded assets.

For smaller dbt projects, where compilation time is not a concern, the simplest way to load your dbt assets into Dagster is the following:

```python
from dagster_dbt import load_assets_from_dbt_project

dbt_assets = load_assets_from_dbt_project(
    project_dir="path/to/dbt/project"
)
```

The `load_assets_from_dbt_project` function:

1. Compiles your dbt project,
2. Parses the metadata that dbt provides, and
3. Generates a set of software-defined assets that reflect the models in the project. These assets will share the same underlying operation, which will invoke dbt to run the models represented by the loaded assets.

### Loading dbt models from a dbt manifest.json file

For larger projects, recompiling the entire project when the repository needs to be loaded may be a concern. In these cases, you can load dbt models from a dbt `manifest.json` file:

```python
import json
from dagster_dbt import load_assets_from_dbt_manifest

dbt_assets = load_assets_from_dbt_manifest(
    json.load("path/to/dbt/manifest.json", encoding="utf8"),
)
```

Note: if you make any changes to your dbt project that change the structure of the project (such as changing the dependencies of a model or adding a new one), you'll need to regenerate your manifest file for those changes to be reflected in Dagster.

## Adding a resource

In order to function, these assets require a "dbt" resource, which will be responsible for firing off dbt cli commands. The `dagster-dbt` integration provides the `dbt_cli_resource` to make this easy. This resource can be configured with CLI flags that will be passed i

You can configure this resource and add it to your dbt assets:

```python
from dagster import with_resources
from dagster_dbt import dbt_cli_resource

dbt_assets = with_resources(
    load_assets_from_dbt_project(...),
    {
        "dbt": dbt_cli_resource.configured(
            {"project_dir": "path/to/dbt_project"}
        )
    }
)
```

## Scheduling dbt jobs

Once you have your dbt assets, it's simple to define a job that runs some or all of these assets on a schedule

```python
from dagster import ScheduleDefinition, define_asset_job

run_everything_job = define_asset_job("run_everything", selection="*")

# only my_model and its children
run_something = define_asset_job("run_something", selection="my_model*")

@repository
def my_repo():
    return [
        dbt_assets,
        ScheduleDefinition(
            job=run_something,
            cron_schedule="@daily",
        ),
        ScheduleDefinition(
            job=run_everything,
            cron_schedule="@weekly",
        )
    ]
```

See (docs for running stuff on a schedule) to learn more.

## Defining Downstream Dependencies

Dagster allows you to define assets that are downstream of specific dbt models. One property of dbt-based assets is that the external tool - in this case, dbt - handles the loading/storing of those models internally, rather than Dagster directly storing/loading the tables that are updated.

This means that there's a range of ways to load a dbt model as input to a Python function. For example, you might want to load the contents as a Pandas dataframe or into a PySpark session.

To define how assets should be loaded, you can specify an input manager on the downstream asset.

```python
from dagster import asset

@asset(
    ins={"model_name": AssetIn(input_manager_key="pandas_dbt_input_manager")}
)
def my_downstream_asset(model_name):
    return
```

## Customizing AssetKeys

Dagster automatically generates AssetKeys for each dbt model in the project and the sources used by the models.

The default asset key for a model will be the model name, and the default name for a source in the project will be the name of the source alongside the name of the source table.

For example, a model defined in `my_model.sql` will be given the asset key `my_model`, while the source table defined in the following `sources.yaml` will be `jaffle_shop/orders`:

```yaml
sources:
  - name: jaffle_shop
    tables:
      - name: orders
```

You may have a different organization scheme for your asset keys, and therefore want to generate different keys for your dbt models.

### Adding a prefix to AssetKeys

A common pattern is to use the prefix of an asset key to indicate what database an asset is stored in. For example, you might want all of your assets stored in Snowflake to start with the prefix "snowflake". To add a prefix to the models generated by your dbt project, you can pass in a "key_prefix" argument to either the load_assets_from_dbt_manifest or load_assets_from_dbt_project functions.

```python
dbt_assets = load_assets_from_dbt_project(
    ..., key_prefix="snowflake"
)
```

This prefix will apply only to the models. If you want to apply a prefix to the source keys that dagster generates:

```python

dbt_assets = load_assets_from_dbt_project(
    ..., key_prefix="snowflake", source_key_prefix="snowflake"
)
```

### Fully customizing AssetKeys

Sometimes, you want to have full control over what asset key you generate. You can do this by setting the `node_info_to_asset_key` parameter to a function that takes a dictionary of dbt node info (parsed from the dbt manifest) and returns an asset key. This dictionary contains (link to doc).

## Conclusion

If you find a bug or want to add a feature to the `dagster-dbt` library, we invite you to [contribute](/community/contributing).

If you have questions on using dbt with Dagster, we'd love to hear from you:

<p align="center">
  <a href="https://dagster-slackin.herokuapp.com/" target="_blank">
    <Image
      alt="join-us-on-slack"
      src="/assets/join-us-on-slack.png"
      width="160"
      height="40"
    />
  </a>
</p>
