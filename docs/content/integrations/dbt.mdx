---
title: Dagster with dbt
description: Dagster can orchestrate dbt alongside other technologies.
---

## Using dbt with Dagster

Dagster orchestrates dbt alongside _other technologies_, so you can combine dbt with Spark, Python, etc. in a single workflow. Dagster's software-defined asset (SDA) abstractions make it simple to define data assets that depend on specific dbt models, or to define the computation required to compute the sources that your dbt models depend on.

This guide focuses on how to work with `dbt` models through the SDA framework, which we recommend for most use cases.

## dbt Models and Software-Defined Assets

A software-defined asset contains an asset key, a set of upstream asset keys, and an operation that is responsible for computing the asset from its upstream dependencies. Models defined in a `dbt` project are conceptually similar to Dagster's software-defined assets:

- The asset key for a dbt model is (by default) the name of the model.
- The upstream dependencies of a dbt model are defined with `ref` or `source` calls within the model's definition.
- The computation required to compute the asset from its upstream dependencies is the SQL within the model's definition.

These similarities make it natural to interact with dbt models as SDAs. Dagster has built-in support for loading dbt models, seeds, and snapshots as SDAs, allowing you to define Dagster assets that depend on dbt models, or to define the computations that generate sources for your dbt project and have Dagster automatically orchestrate those computations alongside dbt.

### Loading dbt models from a dbt project

For smaller dbt projects, where compilation time is not a concern, the simplest way to load your dbt assets into Dagster is the following:

```python
from dagster_dbt import load_assets_from_dbt_project

dbt_assets = load_assets_from_dbt_project(
    project_dir="path/to/dbt/project"
)
```

The `load_assets_from_dbt_project` function:

1. Compiles your dbt project,
2. Parses the metadata that dbt provides, and
3. Generates a set of software-defined assets that reflect the models in the project. These assets will share the same underlying operation, which will invoke dbt to run the models represented by the loaded assets.

For larger projects, the overhead involved with recompiling the entire project may be a concern. In these cases, you can load dbt models from an existing dbt `manifest.json` file:

```python
import json
from dagster_dbt import load_assets_from_dbt_manifest

dbt_assets = load_assets_from_dbt_manifest(
    json.load("path/to/dbt/manifest.json", encoding="utf8"),
)
```

Note: if you make any changes to your dbt project that change the structure of the project (such as changing the dependencies of a model or adding a new one), you'll need to regenerate your manifest file for those changes to be reflected in Dagster.

## Adding a resource

In order to be executed, these assets require a dbt resource, which will be responsible for firing off dbt cli commands. The `dagster-dbt` integration provides the `dbt_cli_resource` for this purpose. This resource can be configured with CLI flags that will be passed into every dbt invocation.

The most important flag to set is the `project_dir` flag, which points Dagster at the directory of your dbt project, but a complete list of configuration options can be found in the [dbt_cli_resource API docs](https://docs.dagster.io/_apidocs/libraries/dagster-dbt#dagster_dbt.dbt_cli_resource).

You can configure this resource and add it to your dbt assets by doing the following:

```python
from dagster import with_resources
from dagster_dbt import dbt_cli_resource

dbt_assets = with_resources(
    load_assets_from_dbt_project(...),
    {
        "dbt": dbt_cli_resource.configured(
            {"project_dir": "path/to/dbt_project"}
        )
    }
)
```

## Scheduling dbt jobs

Once you have your dbt assets, you can define a job that runs some or all of these assets on a schedule:

```python
from dagster import ScheduleDefinition, define_asset_job

run_everything_job = define_asset_job("run_everything", selection="*")

# only my_model and its children
run_something = define_asset_job("run_something", selection="my_model*")

@repository
def my_repo():
    return [
        dbt_assets,
        ScheduleDefinition(
            job=run_something,
            cron_schedule="@daily",
        ),
        ScheduleDefinition(
            job=run_everything,
            cron_schedule="@weekly",
        )
    ]
```

See the docs on [running jobs on a schedule](https://docs.dagster.io/concepts/partitions-schedules-sensors/schedules#running-the-scheduler) to learn more.

## Defining Downstream Dependencies

Dagster allows you to define assets that are downstream of specific dbt models. One property of dbt-based assets is that the external tool - in this case, dbt - handles storing each model in the database internally, rather than Dagster directly storing the tables that are updated.

This means that there's a range of ways to load a dbt model as input to a Python function. For example, you might want to load the contents as a Pandas dataframe or into a PySpark session. You can specify this loading behavior on each downstream asset. For example, if you wanted to consume a dbt model named `my_dbt_model` as a Pandas DataFrame, that would look something like the following:

```python
@asset(
    ins={"my_dbt_model": AssetIn(input_manager_key="pandas_df_manager")}
)
def my_downstream_asset(my_dbt_model):
    # my_dbt_model is a Pandas DataFrame
    return my_dbt_model.where(foo="bar")
```

### Defining your IOManager

The implementation of your IOManager will depend on what python object you want to use to represent your table, as well as what database you're loading from. A simple IOManager implementation that loads data from a dbt-managed table into a Pandas DataFrame would look somthing like the following:

```python
import pandas as pd
from dagster import IOManager, io_manager

class PandasIOManager(IOManager):

    def __init__(self, con_string: str):
        self._con = con_string

    def load_input(self, context) -> pd.DataFrame:
        """Load the contents of a table as a pandas DataFrame."""
        table_name = context.upstream_output.asset_key.path[-1]
        return pd.read_sql(f"SELECT * FROM {table_name}", con=self._con)


@io_manager(config_schema={"con_string": str})
def pandas_io_manager(context):
    return PandasIOManager(context.resource_config["con_string"])
```

Once your IOManager is defined, you can supply it just like any other resource when calling `with_resources`:

```python
from dagster import with_resources
from dagster_dbt import dbt_cli_resource

dbt_assets = with_resources(
    load_assets_from_dbt_project(...),
    {
        "dbt": dbt_cli_resource.configured(
            {"project_dir": "path/to/dbt_project"}
        ),
        "pandas_df_manager": pandas_io_manager.configured(
            {"con_string": "..."}
        )
    }
)
```

## Understanding AssetKeys

In Dagster, each asset has an asset key to identify it. Dagster automatically generates these keys for each dbt node in the project as well as the sources for each node.

For models, seeds, and snapshots, the default asset key will be the configured schema for that node (if any), concatenated with the name of the node.

For example, if you have configured a [custom schema](https://docs.getdbt.com/docs/building-a-dbt-project/building-models/using-custom-schemas) for a subdirectory in your `dbt_project.yml` file:

```yaml
models:
  my_project:
    marketing:
      +schema: marketing
```

Then the asset key for a model named "some_model" will be `marketing/some_model`. If you have not configured a custom schema, then the asset key will simply be `some_model`.

For sources, the default asset key will be the name of the source concatenated with the name of the source table.

For example, the source table defined in the following `sources.yaml` will be `jaffle_shop/orders`:

```yaml
sources:
  - name: jaffle_shop
    tables:
      - name: orders
```

### Adding a prefix to AssetKeys

A common pattern is to use the prefix of an asset key to indicate what database an asset is stored in. For example, you might want all of your assets stored in Snowflake to start with the prefix `snowflake`. To add a prefix to the models generated by your dbt project, you can pass in a `key_prefix` argument to either the `load_assets_from_dbt_manifest` or `load_assets_from_dbt_project` function.

```python
dbt_assets = load_assets_from_dbt_project(
    ..., key_prefix="snowflake"
)
```

This prefix will apply only to the models. If you want to apply a prefix to the source keys that dagster generates:

```python

dbt_assets = load_assets_from_dbt_project(
    ..., source_key_prefix="snowflake"
)
```

## Conclusion

If you find a bug or want to add a feature to the `dagster-dbt` library, we invite you to [contribute](/community/contributing).

If you have questions on using dbt with Dagster, we'd love to hear from you:

<p align="center">
  <a href="https://dagster-slackin.herokuapp.com/" target="_blank">
    <Image
      alt="join-us-on-slack"
      src="/assets/join-us-on-slack.png"
      width="160"
      height="40"
    />
  </a>
</p>
