---
title: "Migrating Airflow to Dagster"
description: guide for doing a lift and shift migration of airflow to dagster
---

# Migrating Airflow to Dagster

<Note>
  Looking for an example of an Airflow to Dagster migration? Check out the{" "}
  <a href="https://github.com/dagster-io/dagster-airflow-migration-example">
    dagster-airflow migration example repo on GitHub
  </a>
  !
</Note>

Dagster can convert your Airflow DAGs into Dagster jobs, enabling a lift-and-shift migration from Airflow to Dagster without any rewriting.

This guide will walk you through the steps of doing this migration.

---

## Step 1: Take inventory of your existing Airflow usage

Making migrations is complicated, there are lots of moving pieces and it will be important for you to go in knowing exactly how much scope and complexity you'll be tackling.

There are a few things you'll want to do ahead of time, specifically you'll want to make a note of:

- what operator types the dags you're migrating use
- what airflow connections your dags depend on
- what airflow variables you have set
- what airflow secrets backend you use
- where are the permissions that your dags depend on defined

If you're unsure where to find these things its likely that you're not the right person to make the migration.

---

## Step 2: Prepare your project for a new Dagster python module

There can be a ton of ways of structuring an airflow git repository, for the sake of this migration guide we'll assume that you're using a repository structure that contains a single `./dags` DagBag directory which contains all your dags. We'd then recommend making a `dagster_migration.py` in the root of your repository.

---

## Step 3: Install dagster, dagster-airflow and dagit alongside airflow

You will need to install the `dagster`, `dagster-airflow`, and `dagit` Python packages besides airflow, beware, this might be difficult and could require working through a bunch of different version pins. Installing Airflow 1.x.x versions might be particularly challenging since the constraint files provided for them are usually outdated. Do not get discouraged if you run into problems here, and don't hesitate to reach out for help in the dagster slack.

```bash
pip install dagster dagster-airflow dagit
```

We'd strongly recommend using a virtualenv for this and to also validate that you're installing the correct versions of your airflow dependencies, you can validate this by looking in your airflow providers ui and spot checking version numbers, doing this upfront will likely save you from having to debug tricky errors caused by using a different dependency version from what your airflow DAG expects

---

## Step 4: Create new dagster definitions using make_dagster_definitions_from_airflow_dags_path

Next you can start writing python! woo! In your `dagster_migration.py` you'll use <PyObject module="dagster_airflow" object="make_dagster_definitions_from_airflow_dags_path" /> and pass it the file path of your Airflow DagBag. Dagster will then load the DagBag and convert all DAGs into Dagster jobs and schedules.

```python file=/integrations/airflow/migrate_repo.py
import os

from dagster_airflow import (
    make_dagster_definitions_from_airflow_dags_path,
)

migrated_airflow_definitions = make_dagster_definitions_from_airflow_dags_path(
    os.path.abspath("./dags/"),
)
```

---

## Step 5: Run dagit and verify your DAGs are loading

now we'll get everything running locally, beware your migrated DAGs are very unlikely to execute correctly at this point (unless you have very very simple DAGs) since we've not yet ported any airflow configuration. But being able to start our or development loop of:

- making a code change locally
- running dagster locally
- viewing and debuging any errors
- repeat

```bash
dagster dev -f ./migrate_repo.py
```

After open the dagit UI in your browser you should see a list of Dagster Jobs corresponding to the DAGs in your Airflow DagBag. Pick one of the more simple Jobs, ideally one you are familiar with the business logic, and run it. It will likely fail. But you can look at your stdout/stderr to find out why and start addressing what will likely be a large list of configuration and permission issues.

---

## Step 6: transfer your Airflow configuration

For porting airflow configuration we'd recommend leaning on Environment variables as much as possible, specifically a .env in the root of your project filled with airflow variables and/or a secrets backends configuration.

Seperately you'll also need to configure any [Airflow connections](https://airflow.apache.org/docs/apache-airflow/stable/howto/connection.html) that your DAG depends on. To do this we'd recommend using our `connections` parameter to the dagster-airflow apis instead of uri encoded environment variables.

```python file=/integrations/airflow/migrate_repo_connections.py
import os

from airflow.models import Connection
from dagster_airflow import (
    make_dagster_definitions_from_airflow_dags_path,
)

migrated_airflow_definitions = make_dagster_definitions_from_airflow_dags_path(
    os.path.join(os.environ["AIRFLOW_HOME"], "dags"),
    connections=[
        Connection(conn_id="http_default", conn_type="uri", host="https://google.com")
    ],
)
```

It will likely take quite of bit of trial and error to get all your airflow config correctly ported to your local environment, luckily you should have a tight local iteration loop when doing this work.

---

## Step 7: Going to production

Your migrated airflow DAGs should be able to on both OSS and Dagster Cloud however in this guide we'll focus on running in Cloud. First follow the instructions in the [Dagster Cloud getting started guide](/dagster-cloud/getting-started)

Once you have your dagster cloud organization setup you can either choose to adapt your existing airflow repository to use the Dagster Cloud CI/CD deployment or copy over your code to the quickstart repository you made.

We'd really recommend waiting to go to production till you've first got your airflow DAGs executing successfully in your local development environment.

---

## Step 8: Migrating Permissions

Your Airflow instance likely had specific IAM or Kubernetes permissions that allowed it to successfully run your Airflow DAGs. In order to run the migrated Dagster jobs, you'll need to duplicate these permissions for Dagster.

- **We'd recommend using [Airflow connections](https://airflow.apache.org/docs/apache-airflow/stable/howto/connection.html) or [environment variables](/dagster-cloud/developing-testing/environment-variables-and-secrets)** to define permissions whever possible.

- If you're uncomfortable or unable to use Airflow connections or environment variables you can also attached permissions directly to the infrastructure you're deploying dagster onto.

- **If your Airflow DAGs used [`KubernetesPodOperators`](https://airflow.apache.org/docs/apache-airflow-providers-cncf-kubernetes/stable/operators.html)**, it's possible that you used the `in_cluster` config or loading a `kube_config` file. When migrating, we recommend switching to [using connections with a `kube_config` JSON blob](https://airflow.apache.org/docs/apache-airflow-providers-cncf-kubernetes/stable/connections/kubernetes.html) to make things easier.

---

## Limitations

There are a few limitations to converting Airflow DAGs into Dagster Jobs, Assets, and Schedules. The following features are currently unsupported:

- `retry-from-failure` in Dagster
- Using `prev_execution_date` in Airflow-templated DAGs
- `SubDAGOperators`
- Airflow Datasets
- Airflow Pools

Most of the current limitations are due to a locally-scoped, ephemeral Airflow database being created for each run. If your DAGs implicitly rely on Airflow database state across `DagRuns`, then the current migration tooling won't work for you.

Note that we are working on extending support for these features. If interested in them, let us know in the #dagster-airflow channel of the Dagster Slack.

---

## Containerized Operator Considerations

There are a variety of Airflow Operator types that are used to create container runs in various container execution environments, for example kubernetes or amazon ECS, when getting things working locally we'd recommend trying to execute those containers locally whenever possible and only relying on remote execution when its either unrealistic or impossible to locally emulate the cloud environment. For doing local execution it likely means that you will need to have a local kubernets cluster running, we'd recommnd docker's built in k8s environment, and to be able to pull down the container images that will be needed for execution to your local machine.
