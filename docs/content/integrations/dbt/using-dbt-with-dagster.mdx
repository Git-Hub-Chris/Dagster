---
title: "Using Dagster with dbt"
description: Dagster can orchestrate dbt alongside other technologies.
---

# Using dbt with Dagster

<Note>
  Using dbt Cloud? Check out the{" "}
  <a href="/integrations/dbt/using-dbt-cloud-with-dagster">
    dbt Cloud with Dagster guide
  </a>
  !
</Note>

Using Dagster, you can combine dbt and the other technologies in your stack - Spark, Python, and so on - into a single data pipeline. You could, for example:

- Run your dbt models after ingesting data into your data warehouse
- Selectively materialize dbt models and their dependencies
- TODO: what else?

In this tutorial, we'll walk you through integrating dbt with Dagster using dbt's example [jaffle shop project](https://github.com/dbt-labs/jaffle_shop), the [dagster-dbt library](/\_apidocs/libraries/dagster-dbt), and a DuckDB database. By the end of this tutorial, you will:

- Understand how dbt models and Dagster [software-defined assets](/concepts/assets/software-defined-assets) (or SDAs) work together
- Load existing dbt models into a Dagster project as SDAs
- Materialize the assets using Dagit, Dagster’s web UI
- Add upstream and downstream dependencies

---

## dbt models and Dagster software-defined assets

- Section goal: Explain dbt models and Dagster assets; show how they’re alike and fit together. Lead into the tutorial.

Dagster’s [software-defined assets](/concepts/assets/software-defined-assets) (SDAs) bear a number of similarities to dbt models. At a high level, SDAs and dbt models both contain todo

Let’s take a look at a dbt model and an SDA, in code:

<TODO>ADD CODE EXAMPLE</TODO>

Here's what's happening in this example:

<TODO></TODO>

---

## Prerequisites

To complete this tutorial, you'll need:

- **To install the following**:
   - **dbt and Dagster**. Refer to the [dbt](https://docs.getdbt.com/dbt-cli/install/overview) and [Dagster](/getting-started/install) installation docs for more info.
   - **The dbt-duckdb adapter.** This tutorial uses [DuckDB](https://docs.getdbt.com/reference/warehouse-profiles/duckdb-profile) as the database backing dbt. Run the following to install the adapter:

    ```shell
    pip install dbt-duckdb
    ```
   - **The dagster-dbt library.** This library allows you to integrate dbt with Dagster. Run the following to install the library:

      ```shell
      pip install dagster-dbt
      ```
   - **The pandas Python library.** This tutorial uses [pandas](https://pandas.pydata.org/docs/index.html) to fetch raw data. Run the following to install the library:

      ```shell
      pip install pandas
      ```
   - **The plotly Python library**. This tutorial uses [plotly](https://plotly.com/python/) to create a histogram asset. Run the following to install the library:

   ```shell
   pip install plotly
   ```
- **An existing dbt project.** This tutorial uses dbt's example [jaffle shop project](https://github.com/dbt-labs/jaffle_shop), but you can follow along with a different project.

---

## Step 1: Set up the dbt project

First, you'll set up the dbt project for the tutorial. We're using dbt's example [jaffle shop project](https://github.com/dbt-labs/jaffle_shop), but you can follow along with a different project as well.

In this step, you'll:

- [Clone the jaffle_shop dbt project](todo)
- [Create a DuckDB connection profile](todo)
- [Configure the project's `dbt_project.yml` file](todo)

### Step 1.1: Clone the jaffle_shop dbt project

1. In the terminal, create a folder named `dbt_dagster_tutorial`:

   ```shell
   mkdir dbt_dagster_shell
   ```

2. Navigate into the new folder:

   ```shell
   cd dbt_dagster_tutorial
   ```

3. In the `dbt_dagster_tutorial` folder, clone the `jaffle_shop` dbt project:

   ```shell
   git clone https://github.com/dbt-labs/jaffle_shop.git
   ```

The folder structure should now be similar to the following:

```yaml file=/integrations/dbt/dbt_dagster_tutorial/project_structure.yaml startafter=initial_structure_start endbefore=initial_structure_end
dbt_dagster_tutorial └── jaffle_shop ├── README.md ├── dbt_project.yml ├── models │  ├── customers.sql │  ├── orders.sql │  ├── schema.yml │  └── staging │     ├── schema.yml │     ├── stg_customers.sql │     └── stg_orders.sql └── seeds
```

### Step 1.2: Create a DuckDB profile

In this step, you'll add a DuckDB profile to the dbt project. This will allow you to connect dbt to the DuckDB database.

In our example code (viewable [here](TODO)), we've created this file in `/dbt_dagster_tutorial/jaffle_shop/config/profiles.yml`:

```yaml file=../../dbt_dagster_tutorial/jaffle_shop/config/profiles.yml
jaffle_shop:
  target: local
  outputs:
    local:
      type: duckdb
      path: tutorial.duckdb
      schema: jaffle_shop
```

### Step 1.3: Configure the dbt_project.yml file

In this step, you'll verify that your dbt project's `dbt_project.yml` file is correctly configured. To work with this tutorial, this file must:

- Specify `jaffle_shop` as the `profile`:

  ```yaml
  profile: 'jaffle_shop'
  ```

- Specify that `jaffle_shop` models are materialized into tables:

  ```yaml
  models:
    jaffle_shop:
      +materialized: table
  ```

---

## Step 2: Configure dbt model data sources

Next, you'll tell the models in your dbt project where the source data they depend on will be located. There isn't any data yet - in the next section, we'll create Dagster assets that fetch and provide data to the dbt models.

1. [Declare a source](https://docs.getdbt.com/docs/building-a-dbt-project/using-sources#declaring-a-source) by creating a `sources.yml` file in `/dbt_dagster_tutorial/jaffle_shop/models`. This defines the location of tables containing source data:

   ```yaml file=../../dbt_dagster_tutorial/jaffle_shop/models/sources.yml
   version: 2

   sources:
     - name: jaffle_shop
       tables:
         - name: orders_raw
         - name: customers_raw
   ```

2. Update the models in `dbt_dagster_tutorial/jaffle_shop/models/staging` to [select data from the sources you just declared](https://docs.getdbt.com/docs/building-a-dbt-project/using-sources#selecting-from-a-source).

   To do this, update the models' `FROM` statement to use the [`{{ source()}}` function](https://docs.getdbt.com/reference/dbt-jinja-functions/source). When finished, the files should look like the following:

   - For `stg_customers.sql`:

     ```sql file=../../dbt_dagster_tutorial/jaffle_shop/models/staging/stg_customers.sql
     select
         id as customer_id,
         first_name,
         last_name

     from {{ source('jaffle_shop', 'customers_raw') }}
     ```

   - For `stg_orders.sql`:

     ```sql file=../../dbt_dagster_tutorial/jaffle_shop/models/staging/stg_orders.sql
     select
         id as order_id,
         user_id as customer_id,
         order_date,
         status

     from {{ source('jaffle_shop', 'orders_raw') }}
     ```

---

## Step 3: Create Dagster assets and load dbt models

In this step, you'll:

- TODO: Add a dagster directory under dbt_dagster_tutorial
- Create the assets
- Load the dbt models into Dagster
- Supply resources

### Step 3.2: Create the Dagster assets

To fetch the data the dbt models require, we'll write two Dagster assets: one for `customers` and one for `orders`.

1. In the `dagster_code` folder you created in the previous step, create a file named `assets.py`.

2. In `assets.py`, add the following code:

   ```python
   import pandas as pd
   from dagster import asset

   @asset(key_prefix=["jaffle_shop"], group_name="staging")
   def customers_raw() -> pd.DataFrame:
       data = pd.read_csv("https://docs.dagster.io/assets/customers.csv")
       return data

   @asset(key_prefix=["jaffle_shop"], group_name="staging")
   def orders_raw() -> pd.DataFrame:
       data = pd.read_csv("https://docs.dagster.io/assets/orders.csv")
       return data
   ```

Let's take a closer look at the arguments we've provided:

- `group_name` - When Dagster loads the dbt models as assets, the assets will be placed in an asset group based on the name of the folder (`staging`) containing the models. Because we want the assets we add to be included in the same group, we defined this as `staging`.

- `key_prefix` - When the assets are materialized, Dagster will store them in DuckDB in the schema defined by the last value in `key_prefix`. In this case, that's `jaffle_shop`. The tables will have the same names as the assets that produced them, which are `customers_raw` and `orders_raw`.

   Because these tables will become the source data for the `stg_customers.sql` and `stg_orders.sql` models in the dbt project, the names of the assets must match the table names specified in `/dbt_dagster_tutorial/jaffle_shop/models/sources.yml`.

### Step 3.3: Load the dbt models as assets

Next, we'll load the dbt models into Dagster as assets. This step requires the [`dagster-dbt`](TODO) library.

1. In `assets.py`, add the following lines to the top of the file:

   ```python
   from dagster_dbt import load_assets_from_dbt_project
   from dagster._utils import file_relative_path
   ```

   The file should now look like this:

   ```python
   import pandas as pd
   from dagster import asset
   from dagster_dbt import load_assets_from_dbt_project
   from dagster._utils import file_relative_path
   ```

2. After the `orders_raw` asset in `assets.py`, add the following:

   ```python
   DBT_PROJECT_PATH = file_relative_path(__file__, "../jaffle_shop")
   DBT_PROFILES = file_relative_path(__file__, "../jaffle_shop/config")

   dbt_assets = load_assets_from_dbt_project(
       project_dir=DBT_PROJECT_PATH, profiles_dir=DBT_PROFILES, key_prefix=["jaffle_shop"]
   )
   ```

Here, we're using the <PyObject module="dagster_dbt" object="load_assets_from_dbt_project" /> function to load the models into Dagster as assets. This creates one Dagster asset for each dbt model.

Let's take a look at the arguments we've supplied:

- `project_dir`, which is the path to the dbt project
- `profiles_dir`, which is the path to the dbt project's connection profiles
- `key_prefix`, which is a prefix to apply to all models in the dbt project

When invoked, this function:

1. Compiles your dbt project using the provided arguments,
2. Parses the metadata provided by dbt, and
3. Generates a set of software-defined assets reflecting the models in the project. These assets share the same underlying operation, which will invoke dbt to run the models represented by the loaded assets.

At this point, `assets.py` should look like this:

```python
import pandas as pd
from dagster import asset
from dagster_dbt import load_assets_from_dbt_project
from dagster._utils import file_relative_path


@asset(key_prefix=["jaffle_shop"], group_name="staging")
def customers_raw() -> pd.DataFrame:
    data = pd.read_csv("https://docs.dagster.io/assets/customers.csv")
    return data


@asset(key_prefix=["jaffle_shop"], group_name="staging")
def orders_raw() -> pd.DataFrame:
    data = pd.read_csv("https://docs.dagster.io/assets/orders.csv")
    return data


DBT_PROJECT_PATH = file_relative_path(__file__, "../jaffle_shop")
DBT_PROFILES = file_relative_path(__file__, "../jaffle_shop/config")

dbt_assets = load_assets_from_dbt_project(
    project_dir=DBT_PROJECT_PATH, profiles_dir=DBT_PROFILES, key_prefix=["jaffle_shop"]
)
```

---

## Step 4: Add a downstream asset

---

## Step 5: Materialize the assets

TODO
