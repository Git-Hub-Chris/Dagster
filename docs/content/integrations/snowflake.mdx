---
title: "Using Dagster with Snowflake"
description: Store your Dagster assets in Snowflake
---

# Using Dagster with Snowflake

This guide focuses on how to store and load Dagster's [software-defined assets (SDAs)](/concepts/assets/software-defined-assets) in Snowflake.

## Prerequisites

To use the Snowflake I/O manager, you will need to gather the following information:

- **Snowflake account name**: You can find this by logging into Snowflake and getting the account name from the URL.

  <Image
  src="/images/integrations/snowflake/snowflake-account.png"
  width={1456}
  height={72}
  />

- **Snowflake credentials**: This includes a username and a password. The Snowflake I/O manager can read these values from environment variables. In this guide, we store the username and password as `SNOWFLAKE_USER` and `SNOWFLAKE_PASSWORD`, respectively.

  ```shell
  export SNOWFLAKE_USER=<your username>
  export SNOWFLAKE_PASSWORD=<your password>
  ```

You will also need to install the `dagster-snowflake` and `dagster-snowflake-pandas` libraries:

```shell
pip install dagster-snowflake dagster-snowflake-pandas
```

### Concepts

This guide assumes you are familiar with Dagster's software-defined assets and I/O managers. For more information on software-defined assets, see the [Assets tutorial](/tutorial/defining-an-asset) or the [Assets concept page](/concepts/assets/software-defined-assets). For more information on I/O managers, see the [I/O manager concept page](/concepts/io-management/io-managers)

## Step 1: Configure the Snowflake I/O manager

<TabGroup>

<TabItem name="Connection configuration">

### Connecting to Snowflake

The Snowflake I/O manager requires some configuration to connect to your Snowflake instance. The `account`, `user` and `password` are required to connect with Snowflake. You can also provide an optional `role` for the I/O manager. These configuration values can be supplied to the Snowflake I/O manager like this:

```python file=/integrations/snowflake/creds_configuration.py startafter=start_example endbefore=end_example
from dagster_snowflake_pandas import snowflake_pandas_io_manager

from dagster import repository, with_resources


@repository
def flowers_analysis_repository():
    return with_resources(
        [iris_dataset],
        resource_defs={
            "io_manager": snowflake_pandas_io_manager.configured(
                {
                    "account": "abc1234.us-east-1",
                    "user": {"env": "SNOWFLAKE_USER"},
                    "password": {"env": "SNOWFLAKE_PASSWORD"},
                    "role": "reader",
                }
            )
        },
    )
```

The configuration values for the Snowflake I/O manager can be stored in environment variables and referenced in the configuration dictionary. In this example, we are storing the username and password in environment variables and telling the Snowflake I/O manager to find the values in the `SNOWFLAKE_USER` and `SNOWFLAKE_PASSWORD` variables, respectively.

</TabItem>
<TabItem name="Table location configuration">

### Specifying where data is stored

You can also provide configuration to the Snowflake I/O manager that will tell it where to store your data. Specifically, you can tell the Snowflake I/O manager the `warehouse`, `database`, and `schema` where you want to store your data:

```python file=/integrations/snowflake/location_configuration.py startafter=start_example endbefore=end_example
from dagster_snowflake_pandas import snowflake_pandas_io_manager

from dagster import repository, with_resources


@repository
def flowers_analysis_repository():
    return with_resources(
        [iris_dataset],
        resource_defs={
            "io_manager": snowflake_pandas_io_manager.configured(
                {
                    "warehouse": "PLANTS",
                    "database": "FLOWERS",
                    "schema": "IRIS",
                }
            )
        },
    )
```

With this configuration, if you materialized an asset called `iris_dataset`, Dagster would store the data in the `FLOWERS.IRIS.IRIS_DATASET` table.g

Providing a `warehouse` and `schema` is optional. If you do not provide a warehouse, the default warehouse for your account will be used. If you do not provide a schema, Dagster will either infer a schema from your assets, or store the tables in the `PUBLIC` schema (see [Storing tables in multiple schemas](#storing-tables-in-multiple-schemas) for more information).
</TabItem>
</TabGroup>

For more documentation for each of the configuration values, see the **Config schema** dropdown in the [Snowflake API docs](#dagster_snowflake.build_snowflake_io_manager).

## Step 2: Create tables in Snowflake

<TabGroup>

<TabItem name="Create tables in Snowflake from Dagster assets">

### Store a Dagster asset as a table in Snowflake

To store data in Snowflake using the Snowflake I/O manager, the definitions of your assets don't need to change. You can tell Dagster to use the Snowflake I/O Manager in your repository, and Dagster will handle storing and loading your assets in Snowflake.

```python file=/integrations/snowflake/basic_example.py
import pandas as pd
from dagster_snowflake_pandas import snowflake_pandas_io_manager

from dagster import asset, repository, with_resources


@asset
def iris_dataset() -> pd.DataFrame:
    return pd.read_csv(
        "https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data",
        names=[
            "Sepal length (cm)",
            "Sepal width (cm)",
            "Petal length (cm)",
            "Petal width (cm)",
            "Species",
        ],
    )


@repository
def flowers_analysis_repository():
    return with_resources(
        [iris_dataset],
        resource_defs={
            "io_manager": snowflake_pandas_io_manager.configured(
                {
                    "database": "FLOWERS",
                    "schema": "IRIS",
                    "account": "abc1234.us-east-1",
                    "user": {"env": "SNOWFLAKE_USER"},
                    "password": {"env": "SNOWFLAKE_PASSWORD"},
                }
            )
        },
    )
```

In this example, we first define our [asset](/concepts/assets/software-defined-assets). Here, we are fetching the Iris dataset as a Pandas DataFrame and renaming the columns. The type signature of the function tells the I/O manager what data type it is working with so it is important to include the return type `pd.DataFrame`.

In the repository, we add configuration to the `snowflake_pandas_io_manager` to store the asset in the`FLOWERS` database as `IRIS` schema. When the `handle_output` method of the `snowflake_pandas_io_manager` will create the table `FLOWERS.IRIS.IRIS_DATASET` if it does not exist and replace the contents of the table with the value returned from the `iris_dataset` asset.

</TabItem>

<TabItem name="Make existing tables available in Dagster">

### Make an existing table available in Dagster

You may already have tables in Snowflake that you want to make available to other Dagster assets. You can create [source assets](/concepts/assets/software-defined-assets#defining-external-asset-dependencies) for these tables. By creating a source asset for the existing table, you tell Dagster how to find the table, so it can be fetched for downstream assets.

```python file=/integrations/snowflake/source_asset.py
from dagster_snowflake_pandas import snowflake_pandas_io_manager

from dagster import SourceAsset, repository, with_resources

daffodil_dataset = SourceAsset(key="daffodil_dataset")


@repository
def flowers_analysis_repository():
    return with_resources(
        [daffodil_dataset],
        resource_defs={
            "io_manager": snowflake_pandas_io_manager.configured(
                {
                    "database": "FLOWERS",
                    "schema": "DAFFODIL",
                    "account": "abc1234.us-east-1",
                    "user": {"env": "SNOWFLAKE_USER"},
                    "password": {"env": "SNOWFLAKE_PASSWORD"},
                }
            )
        },
    )
```

In this example, we create a `SourceAsset` for a pre-existing table containing data about daffodils (perhaps this table is created by an external data ingestion tool). In order to make the data available to other Dagster assets we need to tell the Snowflake I/O manager how to find the data. Since we are supplying the database and the schema in the I/O manager configuration, we only need to provide the table name. We do this with the `key` parameter in `SourceAsset`. When the I/O manager needs to load the `daffodil_dataset` in a downstream asset, it will select the data in the `FLOWERS.DAFFODIL.DAFFODIL_DATASET` table as a Pandas DataFrame and provide it to the downstream asset.

</TabItem>

</TabGroup>

## Step 3: Load Snowflake tables in downstream assets

Once you have created an asset or source asset that represents a table in Snowflake, you will likely want to create additional assets that work with the data. Dagster and the Snowflake I/O manager allow you to load the data stored in Snowflake tables into downstream assets

```python file=/integrations/snowflake/load_downstream.py
import pandas as pd
from dagster_snowflake_pandas import snowflake_pandas_io_manager

from dagster import asset, repository, with_resources


@asset
def iris_dataset() -> pd.DataFrame:
    return pd.read_csv(
        "https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data",
        names=[
            "Sepal length (cm)",
            "Sepal width (cm)",
            "Petal length (cm)",
            "Petal width (cm)",
            "Species",
        ],
    )


@asset
def iris_cleaned(iris_dataset: pd.DataFrame):
    return iris_dataset.dropna().drop_duplicates()


@repository
def flowers_analysis_repository():
    return with_resources(
        [iris_dataset, iris_cleaned],
        resource_defs={
            "io_manager": snowflake_pandas_io_manager.configured(
                {
                    "database": "FLOWERS",
                    "schema": "IRIS",
                    "account": "abc1234.us-east-1",
                    "user": {"env": "SNOWFLAKE_USER"},
                    "password": {"env": "SNOWFLAKE_PASSWORD"},
                }
            )
        },
    )
```

In this example, we create the `iris_dataset` as in the [Store a Dagster asset as a table in Snowflake](#store-a-dagster-asset-as-a-table-in-snowflake) example. In `iris_cleaned` the `iris_dataset` parameter tells Dagster that the value for the `iris_dataset` asset should be provided as input to `iris_cleaned` (if this feels too magical for you, see [this page](/concepts/assets/software-defined-assets#defining-explicit-dependencies) for how to explicitly specify dependencies). When materializing these assets, Dagster will use the `snowflake_pandas_io_manager` to fetch the `FLOWERS.IRIS.IRIS_DATASET` as a Pandas DataFrame and pass this DataFrame as the `iris_dataset` parameter to `iris_cleaned`. When `iris_cleaned` returns a Pandas DataFrame, Dagster will use the `snowflake_pandas_io_manager` to store the DataFrame as the `FLOWERS.IRIS.IRIS_CLEANED` table in Snowflake.
