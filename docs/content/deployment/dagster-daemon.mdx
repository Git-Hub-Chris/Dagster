---
title: Dagster daemon | Dagster
description: Several Dagster features require a long-running daemon process within your deployment.
---

# Dagster daemon

Several Dagster features, like [schedules](/concepts/partitions-schedules-sensors/schedules), [sensors](/concepts/partitions-schedules-sensors/sensors), and [run queueing](/deployment/run-coordinator#limiting-run-concurrency), require a long-running `dagster-daemon` process to be included with your deployment.

---

## Starting the daemon

- [Running locally](#running-locally)
- [Deploying the daemon](#deploying-the-daemon)

### Running locally

The Dagster daemon can be started locally in a few ways, which are outlined in the following tabs. Once started, the process should be kept running.

<TabGroup>
<TabItem name="From a file">

The Dagster daemon can load a file directly as a code location. In the following example, we used the `-f` argument to supply the name of the file to `dagster-daemon`:

```shell
dagster-daemon run -f my_file.py
```

This command loads the definitions in `my_file.py` as a code location in the same Python environment where the daemon resides.

You can also include multiple files at a time:

```shell
dagster-daemon run -f my_file.py -f my_second_file.py
```

---

</TabItem>
<TabItem name="From a module">

The Dagster daemon can also load Python modules as code locations. When this approach is used, Dagster loads the definitions defined at the top-level of the module, in a variable containing the <PyObject object="Definitions" /> object of its root `__init__.py` file. As this style of development eliminates an entire class of Python import errors, we strongly recommend it for Dagster projects deployed to production.

In the following example, we used the `-m` argument to supply the name of the module to the daemon process:

```shell
dagster-daemon run -m your_module_name
```

This command loads the definitions in the variable containing the <PyObject object="Definitions" /> object in the named module - defined as the root `__init__.py` file - in the same virtual environment as the daemon.

---

</TabItem>
<TabItem name="Without command line arguments">

To load definitions without supplying command line arguments, you can use the `pyproject.toml` file. This file, included in all Dagster example projects, contains a `tool.dagster` section with a `module_name` variable:

```shell
[tool.dagster]
module_name = "your_module_name"  ## name of project's Python module
```

When defined, you can run this in the same directory as the `pyproject.toml` file:

```shell
dagster-daemon run
```

Instead of this:

```shell
dagster-daemon run -m your_module_name
```

---

</TabItem>
</TabGroup>

### Deploying the daemon

For information on deploying the daemon to environments like Docker or Kubernetes, refer to the [deployment guides](/deployment/guides).

---

## Available daemons

The `dagster-daemon` process reads from your [Dagster instance](/deployment/dagster-instance) file to determine which daemons should be included. Each of the included daemons then runs on a regular interval in its own threads.

The following daemons are currently available:

<table
  className="table"
  style={{
    width: "100%",
  }}
>
  <thead>
    <tr>
      <th
        style={{
          width: "20%",
        }}
      >
        Name
      </th>
      <th>Description</th>
      <th>Enabled by</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Scheduler daemon</td>
      <td>
        Creates runs from active{" "}
        <a href="/concepts/partitions-schedules-sensors/schedules">schedules</a>
      </td>
      <td>
        Enabled / runs as long as the default{" "}
        <PyObject
          module="dagster._core.scheduler"
          object="DagsterDaemonScheduler"
        />{" "}
        isn't overriden as the scheduler on your instance.
      </td>
    </tr>
    <tr>
      <td>Run queue daemon</td>
      <td>
        Launches queued runs, taking into account any limits and prioritization
        rules set on your instance
      </td>
      <td>
        Setting the <a href="/deployment/run-coordinator">run coordinator</a> on
        your instance to{" "}
        <PyObject
          module="dagster._core.run_coordinator"
          object="QueuedRunCoordinator"
        />
        .
      </td>
    </tr>
    <tr>
      <td>Sensor daemon</td>
      <td>
        Creates runs from active{" "}
        <a href="/concepts/partitions-schedules-sensors/sensors">sensors</a>{" "}
        that are turned on
      </td>
      <td>Always enabled</td>
    </tr>
    <tr>
      <td>Run monitoring daemon</td>
      <td>
        Handles <a href="/deployment/overview#job-execution-flow">run worker</a>{" "}
        failures
      </td>
      <td>
        Using the <code>run_monitoring</code> field in your instance. Refer to
        the{" "}
        <a href="/deployment/run-monitoring">Run monitoring documentation</a>{" "}
        for more info.
      </td>
    </tr>
  </tbody>
</table>

If the daemon is configured to use a [workspace file](/concepts/code-locations/workspace-files) to load code location(s), note that they will periodically reload the file. This means that the `dagster-daemon` process doesn't need to be restarted when workspace files are changed.

---

## Checking daemon status in Dagit

To check the status of the `dagster-daemon` process within Dagit:

1. In the top navigation, click **Deployment**.
2. Click the **Daemons** tab.

This tab displays information about all the daemons currently configured on your instance.

Each daemon periodically writes a heartbeat to your instance storage. If a daemon doesn't show a recent heartbeat, check the logs from your `dagster-daemon` process for errors.
