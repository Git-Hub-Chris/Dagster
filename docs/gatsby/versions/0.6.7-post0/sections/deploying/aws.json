{
  "parents": [{ "link": "../", "title": "Deploying Dagster" }],
  "prev": { "link": "../local/", "title": "Local or Standalone Dagit" },
  "next": { "link": "../gcp/", "title": "GCP Deployment" },
  "title": "AWS Deployment",
  "meta": {},
  "body": "<div class=\"section\" id=\"aws-deployment\">\n<span id=\"deployment-aws\"></span><h1>AWS Deployment<a class=\"headerlink\" href=\"#aws-deployment\" title=\"Permalink to this headline\">\u00b6</a></h1>\n<p class=\"rubric\">Quick Start</p>\n<p><strong>NOTE: The dagster-aws CLI is not intended to provide a secure configuration, and the instance\nlaunched will be publicly accessible. For production settings, you should consider manually\nlaunching a Dagit instance behind your organization\u2019s reverse proxies or within your internal\nnetwork.</strong></p>\n<p>If you are on AWS, there is a quick start CLI utility in <code class=\"docutils literal notranslate\"><span class=\"pre\">dagster-aws</span></code> to automate the setup\nprocess. Ensure you have AWS credentials on your local machine, and run:</p>\n<div class=\"highlight-shell notranslate\"><div class=\"highlight\"><pre><span></span>mkdir -p ~/dagster\n<span class=\"nb\">export</span> <span class=\"nv\">DAGSTER_HOME</span><span class=\"o\">=</span>~/dagster\npip install dagster dagit dagster-aws\ndagster-aws init\n</pre></div>\n</div>\n<p>This script will walk you through setting up an EC2 VM instance to host Dagit, as well as creating a\nsecurity group and key pair along the way. Once completed, the configuration for this is stored on\nyour local machine in <code class=\"docutils literal notranslate\"><span class=\"pre\">$DAGSTER_HOME/.dagit-aws-config</span></code>; subsequent usage of <code class=\"docutils literal notranslate\"><span class=\"pre\">dagster-aws</span></code> will\nuse this configuration to connect to your running EC2 instance.</p>\n<p>This script will optionally launch an RDS instance for you; if you choose to launch an RDS\nPostgreSQL instance, the remote EC2 instance will automatically be configured to talk to RDS via a\n<code class=\"docutils literal notranslate\"><span class=\"pre\">dagster.yaml</span></code> file in the remote <code class=\"docutils literal notranslate\"><span class=\"pre\">$DAGSTER_HOME</span></code>. See the docs on the\n<span class=\"xref std std-ref\">Dagster Instance</span> for more information about this configuration.</p>\n<p>Once the EC2 instance is launched and ready, you can synchronize your Dagster code to it using:</p>\n<div class=\"highlight-shell notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"nb\">cd</span> /path/to/your/dagster/code\ndagster-aws up\n</pre></div>\n</div>\n<p>This will copy over your Dagster client code to the EC2 instance, launch Dagit as <cite>systemd</cite> service,\nand finally print a URL for you to connect to Dagit. You can look at\n<a class=\"reference external\" href=\"https://github.com/dagster-io/dagster/blob/master/python_modules/libraries/dagster-aws/dagster_aws/cli/shell/init.sh\">init.sh</a>\nfor details on how we initialize the VM for running Dagit and the specification of the <code class=\"docutils literal notranslate\"><span class=\"pre\">systemd</span></code>\nservice.</p>\n<p>The <code class=\"docutils literal notranslate\"><span class=\"pre\">dagster-aws</span></code> CLI saves its state to <code class=\"docutils literal notranslate\"><span class=\"pre\">$DAGSTER_HOME/dagster-aws-config.yaml</span></code>, so you can inspect\nthat file to understand what\u2019s going on and/or debug any issues.</p>\n<p class=\"rubric\">EC2 or ECS hosted Dagit</p>\n<p>To host dagit on a bare VM or in Docker on ECS, see the <a class=\"reference external\" href=\"local.html\">Local or Standalone Dagit</a>\nguide.</p>\n<p class=\"rubric\">Execution</p>\n<p>Out of the box, Dagit runs single-process execution. To enable multi-process execution, add the\nfollowing to your pipeline configuration YAML:</p>\n<div class=\"literal-block-wrapper docutils container\" id=\"id1\">\n<div class=\"code-block-caption\"><span class=\"caption-text\">execution_config.yaml</span><a class=\"headerlink\" href=\"#id1\" title=\"Permalink to this code\">\u00b6</a></div>\n<div class=\"highlight-yaml notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"nt\">execution</span><span class=\"p\">:</span>\n  <span class=\"nt\">multiprocess</span><span class=\"p\">:</span>\n    <span class=\"nt\">max_concurrent</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">0</span>\n<span class=\"nt\">storage</span><span class=\"p\">:</span>\n  <span class=\"nt\">filesystem</span><span class=\"p\">:</span>\n</pre></div>\n</div>\n</div>\n<p><strong>NOTE:</strong> This YAML fragment should be put in your pipeline-specific configuration, not in\n<code class=\"docutils literal notranslate\"><span class=\"pre\">$DAGSTER_HOME/dagster.yaml</span></code>. This is designed to permit configuration of execution on a\nper-pipeline. Future versions of Dagster may add support for globally configuring execution.</p>\n<p class=\"rubric\">RDS Run / Events Storage</p>\n<p>On AWS you can use a hosted RDS PostgreSQL database for your Dagster run/events data. As\nnoted previously, this can be accomplished by adding the following to <code class=\"docutils literal notranslate\"><span class=\"pre\">$DAGSTER_HOME/dagster.yaml</span></code>:</p>\n<div class=\"literal-block-wrapper docutils container\" id=\"id2\">\n<div class=\"code-block-caption\"><span class=\"caption-text\">dagster.yaml</span><a class=\"headerlink\" href=\"#id2\" title=\"Permalink to this code\">\u00b6</a></div>\n<div class=\"highlight-yaml notranslate\"><div class=\"highlight\"><pre><span></span> <span class=\"nt\">run_storage</span><span class=\"p\">:</span>\n     <span class=\"nt\">module</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">dagster_postgres.run_storage</span>\n     <span class=\"nt\">class</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">PostgresRunStorage</span>\n     <span class=\"nt\">config</span><span class=\"p\">:</span>\n         <span class=\"nt\">postgres_url</span><span class=\"p\">:</span> <span class=\"s\">&quot;postgresql://{username}:{password}@{host}:5432/{database}&quot;</span>\n\n <span class=\"nt\">event_log_storage</span><span class=\"p\">:</span>\n     <span class=\"nt\">module</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">dagster_postgres.event_log</span>\n     <span class=\"nt\">class</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">PostgresEventLogStorage</span>\n     <span class=\"nt\">config</span><span class=\"p\">:</span>\n         <span class=\"nt\">postgres_url</span><span class=\"p\">:</span> <span class=\"s\">&quot;postgresql://{username}:{password}@{host}:5432/{database}&quot;</span>\n</pre></div>\n</div>\n</div>\n<p>In this case, you\u2019ll want to ensure you provide the right connection strings for your RDS instance,\nand ensure that the node or container hosting Dagit is able to connect to RDS.</p>\n<p class=\"rubric\">S3 Intermediates Storage</p>\n<p>You\u2019ll probably also want to configure an S3 bucket to use for Dagster intermediates (see the\n<a class=\"reference external\" href=\"../tutorial/intermediates.html\">intermediates tutorial guide</a> for more info). Dagster supports\nserializing data passed between solids to S3; to enable this, you need to add S3 storage to your\n<code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">ModeDefinition</span></code>:</p>\n<p>Then, just add the following YAML to your pipeline config:</p>\n<div class=\"literal-block-wrapper docutils container\" id=\"id3\">\n<div class=\"code-block-caption\"><span class=\"caption-text\">execution_config.yaml</span><a class=\"headerlink\" href=\"#id3\" title=\"Permalink to this code\">\u00b6</a></div>\n<div class=\"highlight-yaml notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"nt\">storage</span><span class=\"p\">:</span>\n  <span class=\"nt\">s3</span><span class=\"p\">:</span>\n    <span class=\"nt\">config</span><span class=\"p\">:</span>\n      <span class=\"nt\">s3_bucket</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">your-s3-bucket-name</span>\n</pre></div>\n</div>\n</div>\n<p>With this in place, your pipeline runs will store intermediates on S3 in the location\n<code class=\"docutils literal notranslate\"><span class=\"pre\">s3://&lt;bucket&gt;/dagster/storage/&lt;pipeline</span> <span class=\"pre\">run</span> <span class=\"pre\">id&gt;/intermediates/&lt;solid</span> <span class=\"pre\">name&gt;.compute</span></code></p>\n</div>\n",
  "metatags": "",
  "rellinks": [
    ["genindex", "General Index", "I", "index"],
    ["py-modindex", "Python Module Index", "", "modules"],
    ["sections/deploying/gcp", "GCP Deployment", "N", "next"],
    ["sections/deploying/local", "Local or Standalone Dagit", "P", "previous"]
  ],
  "sourcename": "sections/deploying/aws.rst.txt",
  "toc": "<ul>\n<li><a class=\"reference internal\" href=\"#\">AWS Deployment</a></li>\n</ul>\n",
  "display_toc": false,
  "page_source_suffix": ".rst",
  "current_page_name": "sections/deploying/aws",
  "sidebars": ["globaltoc.html", "searchbox.html"],
  "customsidebar": null,
  "alabaster_version": "0.7.12"
}
