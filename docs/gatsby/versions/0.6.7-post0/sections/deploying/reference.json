{
  "parents": [{ "link": "../", "title": "Deploying Dagster" }],
  "prev": { "link": "../gcp/", "title": "GCP Deployment" },
  "next": { "link": "../other/", "title": "Other Deployment Targets" },
  "title": "Reference",
  "meta": {},
  "body": "<div class=\"section\" id=\"reference\">\n<span id=\"deployment-reference\"></span><h1>Reference<a class=\"headerlink\" href=\"#reference\" title=\"Permalink to this headline\">\u00b6</a></h1>\n<p>Dagster is a layered and pluggable system. It is possible to call the Dagster Python APIs directly\nfrom your own code, to call the <code class=\"docutils literal notranslate\"><span class=\"pre\">dagster</span></code> CLI, to execute GraphQL queries against Dagster using\nthe <code class=\"docutils literal notranslate\"><span class=\"pre\">dagster-graphql</span></code> CLI, to run <code class=\"docutils literal notranslate\"><span class=\"pre\">dagster-graphql</span></code> in containers that can respond to GraphQL\nqueries, to run Dagit on a standalone basis, or to compile Dagster DAGs for scheduling and execution\non Airflow. Individual pipeline runs may be executed on pluggable execution engines, including local\nor remote Dask clusters. Metadata from these executions can be streamed to pluggable local and\nremote storage backends.</p>\n<p>This allows substantial flexibility in your deployment strategies. For example, it is\npossible to point a local instance of Dagit, running on an individual developer\u2019s machine, at the\ncloud storage being used by pipelines scheduled in production in order to inspect intermediate\nartifacts.</p>\n<div class=\"section\" id=\"execution\">\n<h2>Execution<a class=\"headerlink\" href=\"#execution\" title=\"Permalink to this headline\">\u00b6</a></h2>\n<p>Dagster pipelines can be executed in a single process, in multiple processes, or on a variety of\ndistributed compute platforms, by selecting between available executors at pipeline execution time\nusing config. This makes it possible to run a pipeline locally in a single process and then remote\non a production cluster just by switching config settings in Dagit or in the environment dict\nprovided to the Python API.</p>\n<p>Dagster includes out-of-the-box support for local execution in a single process and in multiple\nprocesses with the <a class=\"reference internal\" href=\"../../api/apidocs/execution/#dagster.in_process_executor\" title=\"dagster.in_process_executor\"><code class=\"xref py py-data docutils literal notranslate\"><span class=\"pre\">in_process_executor</span></code></a> and\n<a class=\"reference internal\" href=\"../../api/apidocs/execution/#dagster.multiprocess_executor\" title=\"dagster.multiprocess_executor\"><code class=\"xref py py-data docutils literal notranslate\"><span class=\"pre\">multiprocess_executor</span></code></a>. These executors work well for pipelines of moderate\nsize or if your solids communicate with external systems or clusters (e.g., EMR or Dataproc) to\nrun heavy compute workloads.</p>\n<p>These executors are available by default when executing a pipeline using any\n<a class=\"reference internal\" href=\"../../api/apidocs/pipeline/#dagster.ModeDefinition\" title=\"dagster.ModeDefinition\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">ModeDefinition</span></code></a> that does not define its own executors. By default, in the\nabsence of specific executor config, the in-process executor will be used. To select the\nmultiprocess executor, add a fragment like the following to the config of any pipeline:</p>\n<div class=\"highlight-yaml notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"nt\">execution</span><span class=\"p\">:</span>\n  <span class=\"nt\">multiprocess</span><span class=\"p\">:</span>\n    <span class=\"nt\">max_concurrent</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">4</span>\n<span class=\"nt\">storage</span><span class=\"p\">:</span>\n  <span class=\"nt\">filesystem</span><span class=\"p\">:</span>\n</pre></div>\n</div>\n<p>Note that a persistent system storage, such as the filesystem storage, must be configured in order\nto make multiprocess execution available. This persistent system storage is used to pass\nintermediate values between solids, and incidentally makes reexecution available for all\nmultiprocess executions.</p>\n<p>The <a class=\"reference external\" href=\"https://github.com/dagster-io/dagster/tree/master/python_modules/dagster-dask\">dagster-dask</a>\nmodule makes a <a class=\"reference internal\" href=\"../../api/apidocs/dagster_dask/#dagster_dask.dask_executor\" title=\"dagster_dask.dask_executor\"><code class=\"xref py py-data docutils literal notranslate\"><span class=\"pre\">dask_executor</span></code></a> available, which can target either a local\nDask cluster or a distributed cluster. Computation is distributed across the cluster at the\nexecution step level. This is a straightforward path to testable and scalable distributed\nexecution for heavier workloads.</p>\n<p>As with the multiprocess executor, a persistent system storage must be configured for Dask\nexecution.</p>\n<p>Users can also write their own executors, which can be passed to the <code class=\"docutils literal notranslate\"><span class=\"pre\">executor_defs</span></code> argument on\n<a class=\"reference internal\" href=\"../../api/apidocs/pipeline/#dagster.ModeDefinition\" title=\"dagster.ModeDefinition\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">ModeDefinition</span></code></a>. If you\u2019re considering doing this, please reach out through our\nSlack channel so that we can provide guidance and support.</p>\n</div>\n<div class=\"section\" id=\"scheduling\">\n<h2>Scheduling<a class=\"headerlink\" href=\"#scheduling\" title=\"Permalink to this headline\">\u00b6</a></h2>\n<p>Dagster\u2019s approach to scheduling pipelines for periodic execution is also oriented toward\nextensibility. Schedules are defined in code using the <a class=\"reference internal\" href=\"../../api/apidocs/schedules/#dagster.schedules\" title=\"dagster.schedules\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">&#64;schedules</span></code></a>\nAPI and may be executed by multiple concrete schedulers.</p>\n<p>The first scheduler we\u2019ve built is in the\n<a class=\"reference external\" href=\"https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-cron\">dagster-cron</a>\npackage and is backed by system cron, the <a class=\"reference internal\" href=\"../../api/apidocs/dagster_cron/#dagster_cron.SystemCronScheduler\" title=\"dagster_cron.SystemCronScheduler\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">SystemCronScheduler</span></code></a>. (See the\n<a class=\"reference external\" href=\"scheduling-pipeline-runs\">tutorial docs</a> for an example of how to schedule pipeline executions\nusing the cron-backed scheduler.)</p>\n<p>Users can also write their own schedulers. If you\u2019re considering doing this, please reach out\nthrough our Slack channel so that we can provide guidance and support.</p>\n<div class=\"section\" id=\"compiling-a-pipeline-for-execution-by-a-third-party-scheduler\">\n<h3>Compiling a pipeline for execution by a third-party scheduler<a class=\"headerlink\" href=\"#compiling-a-pipeline-for-execution-by-a-third-party-scheduler\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<p>It\u2019s also possible to schedule pipelines for execution by compiling them to a format that can be\nunderstood by a third-party scheduling system, and then defining schedules within that system.</p>\n<p>This is the approach we use to deploy Dagster pipelines to Airflow (using the\n<a class=\"reference external\" href=\"https://github.com/dagster-io/dagster/tree/master/python_modules/dagster-airflow\">dagster-airflow</a>\npackage).</p>\n<p>A Dagster pipeline is first compiled with a set of config options into an execution plan,\nand then the individual execution steps are expressed as Airflow tasks using a set of custom wrapper\noperators. The resulting DAG can be deployed to an existing Airflow install and scheduled and\nmonitored using all the tools being used to existing pipelines (See the\n<a class=\"reference external\" href=\"other/airflow.html\">Airflow guide</a> for details.)</p>\n<p>If you\u2019re thinking of building a similar integration to target another third-party scheduler, please\nreach out through our Slack channel so that we can provide guidance and support.</p>\n</div>\n</div>\n<div class=\"section\" id=\"storage\">\n<h2>Storage<a class=\"headerlink\" href=\"#storage\" title=\"Permalink to this headline\">\u00b6</a></h2>\n<p>The Dagster tools are built so that the storage backends they use can be easily swapped. This makes\nit easy to swap S3 for GCP (or cloud storage for local) or Postgres for MySQL, guarding against\nlock-in and ensuring compatibility with a wide range of heterogeneous infrastructures. It also\nmakes some neat things possible. For example, a user running a local Dagit can point it at remote\nstorage backends in order to debug or monitor runs being executed on production infrastructure.</p>\n<div class=\"section\" id=\"the-dagsterinstance\">\n<h3>The DagsterInstance<a class=\"headerlink\" href=\"#the-dagsterinstance\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<p>The <a class=\"reference internal\" href=\"../../api/apidocs/internals/#dagster.core.instance.DagsterInstance\" title=\"dagster.core.instance.DagsterInstance\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">DagsterInstance</span></code></a> organizes all of the information specific to\na particular installation or deployment of Dagster. (Locally, this usually means a particular Dagit\nprocess.)</p>\n<p>An instance controls the collection of systems that are used by Dagster for persisting\ndeployment-wide information: the history of past runs, the log of structured events created by\nthose runs, the raw stdout and stderr streams created by those runs, and configuration for the local\nstorage of intermediates.</p>\n<p>These systems are swappable in config, and users can write their own classes to handle persistence\nof any or all of this data. See below for details on how to configure and customize the instance.\n(As always, if you\u2019re interested in extending Dagster, please reach out to us.)</p>\n<p>A Dagster instance is composed of:</p>\n<ul class=\"simple\">\n<li><p><strong>Event Log Storage:</strong> Stores the record of structured events produced during runs. Ideally\nimplementations allow for monitoring the event log in some capacity to enable real time\nmonitoring via Dagit.</p></li>\n<li><p><strong>Run Storage:</strong> Used to keep track of runs over time and query select subsets of them. Separate\nfrom the event log store to allow for efficient queries of run history.</p></li>\n<li><p><strong>Compute Log Manager:</strong> Makes available copies of stdout and stderr on a per execution step basis\nfor debugging. This includes a real time subscription component as well as optional hooks for\nstorage.</p></li>\n<li><p><strong>Local Artifact Storage:</strong> This ensures that a singular directory is used for all the file system\nartifacts produced by Dagster. This is useful for both sharing intermediates across multiple\nexecutions or simply to provide a single point of audit.</p></li>\n</ul>\n<p>Tools like the Dagster CLI or Dagit use the following behavior to select the current instance:</p>\n<ol class=\"arabic simple\">\n<li><p>Use the explicit settings in <code class=\"docutils literal notranslate\"><span class=\"pre\">$DAGSTER_HOME/dagster.yaml</span></code> if they exist</p></li>\n<li><p>Create a local instance rooted at <code class=\"docutils literal notranslate\"><span class=\"pre\">$DAGSTER_HOME</span></code> if it is set</p></li>\n<li><p>Use an ephemeral instance, which will hold information in memory and use a TemporaryDirectory\nfor local artifacts which is cleaned up on exit. This is useful for tests and is the default\nfor direct python api invocations such as <code class=\"docutils literal notranslate\"><span class=\"pre\">execute_pipeline</span></code>.</p></li>\n</ol>\n</div>\n<div class=\"section\" id=\"system-storage-for-intermediate-artifacts\">\n<h3>System storage for intermediate artifacts<a class=\"headerlink\" href=\"#system-storage-for-intermediate-artifacts\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<p>Intermediate persistence is configurable on a per-pipeline run basis. This is so that you can run\npure in-memory tests which don\u2019t persist anything, local runs that persist artifacts to disk for\ndebugging and inspection, and production runs that persist to permanent cloud storage for audit and\nreproducibility.</p>\n<p>Intermediate persistence is governed by subclasses of <a class=\"reference internal\" href=\"../../api/apidocs/internals/#dagster.SystemStorageDefinition\" title=\"dagster.SystemStorageDefinition\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">SystemStorageDefinition</span></code></a>,\nwhich can be attached to a <a class=\"reference internal\" href=\"../../api/apidocs/pipeline/#dagster.ModeDefinition\" title=\"dagster.ModeDefinition\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">ModeDefinition</span></code></a>.</p>\n</div>\n<div class=\"section\" id=\"configuring-an-instance\">\n<h3>Configuring an Instance<a class=\"headerlink\" href=\"#configuring-an-instance\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<p class=\"rubric\">Writing a dagster.yaml</p>\n<p>You can use the explicit settings in <code class=\"docutils literal notranslate\"><span class=\"pre\">$DAGSTER_HOME/dagster.yaml</span></code> to tell Dagster which classes\nto use to manage the event log storage, run log storage, and so forth. This means that these\nstorage classes are pluggable.</p>\n<p>In general, you can tell Dagster which class to use for, e.g., run storage by writing yaml like:</p>\n<div class=\"highlight-YAML notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"nt\">run_storage</span><span class=\"p\">:</span>\n  <span class=\"nt\">module</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">my_very_awesome_module.run_storage</span>\n  <span class=\"nt\">class</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">AwesomeRunStorage</span>\n  <span class=\"nt\">config</span><span class=\"p\">:</span>\n    <span class=\"nt\">secret_word</span><span class=\"p\">:</span> <span class=\"s\">&quot;quux&quot;</span>\n</pre></div>\n</div>\n<p>(If you\u2019re thinking of writing your own class for a case like this, please get in touch \u2013 we can\nhelp you implement the necessary interfaces.)</p>\n<p class=\"rubric\">Using a local or remote Postgres instance for storage</p>\n<p>We\u2019ve written a set of classes (in <code class=\"docutils literal notranslate\"><span class=\"pre\">dagster-postgres</span></code>) which let you target a (local or remote)\nPostgres instance to store information about runs and event logs.</p>\n<p>Make sure that <code class=\"docutils literal notranslate\"><span class=\"pre\">dagster-postgres</span></code> is installed in your Python environment, put the following lines\ninto your <code class=\"docutils literal notranslate\"><span class=\"pre\">dagster.yaml</span></code> (replacing the values for <code class=\"docutils literal notranslate\"><span class=\"pre\">user</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">password</span></code>, the port, and\n<code class=\"docutils literal notranslate\"><span class=\"pre\">db_name</span></code> as needed to target your own local or remote Postgres instance), and then just start\ndagit as normal:</p>\n<div class=\"highlight-YAML notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"nt\">run_storage</span><span class=\"p\">:</span>\n  <span class=\"nt\">module</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">dagster_postgres.run_storage</span>\n  <span class=\"nt\">class</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">PostgresRunStorage</span>\n  <span class=\"nt\">config</span><span class=\"p\">:</span>\n    <span class=\"nt\">postgres_url</span><span class=\"p\">:</span> <span class=\"s\">&quot;postgresql://user:password@instance.us-west-1.rds.amazonaws.com:5432/db_name&quot;</span>\n\n<span class=\"nt\">event_log_storage</span><span class=\"p\">:</span>\n  <span class=\"nt\">module</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">dagster_postgres.event_log</span>\n  <span class=\"nt\">class</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">PostgresEventLogStorage</span>\n  <span class=\"nt\">config</span><span class=\"p\">:</span>\n    <span class=\"nt\">postgres_url</span><span class=\"p\">:</span> <span class=\"s\">&quot;postgresql://user:password@instance.us-west-1.rds.amazonaws.com:5432/db_name&quot;</span>\n</pre></div>\n</div>\n</div>\n</div>\n</div>\n",
  "metatags": "",
  "rellinks": [
    ["genindex", "General Index", "I", "index"],
    ["py-modindex", "Python Module Index", "", "modules"],
    ["sections/deploying/other/index", "Other Deployment Targets", "N", "next"],
    ["sections/deploying/gcp", "GCP Deployment", "P", "previous"]
  ],
  "sourcename": "sections/deploying/reference.rst.txt",
  "toc": "<ul>\n<li><a class=\"reference internal\" href=\"#\">Reference</a><ul>\n<li><a class=\"reference internal\" href=\"#execution\">Execution</a></li>\n<li><a class=\"reference internal\" href=\"#scheduling\">Scheduling</a><ul>\n<li><a class=\"reference internal\" href=\"#compiling-a-pipeline-for-execution-by-a-third-party-scheduler\">Compiling a pipeline for execution by a third-party scheduler</a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#storage\">Storage</a><ul>\n<li><a class=\"reference internal\" href=\"#the-dagsterinstance\">The DagsterInstance</a></li>\n<li><a class=\"reference internal\" href=\"#system-storage-for-intermediate-artifacts\">System storage for intermediate artifacts</a></li>\n<li><a class=\"reference internal\" href=\"#configuring-an-instance\">Configuring an Instance</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n",
  "display_toc": true,
  "page_source_suffix": ".rst",
  "current_page_name": "sections/deploying/reference",
  "sidebars": ["globaltoc.html", "searchbox.html"],
  "customsidebar": null,
  "alabaster_version": "0.7.12"
}
