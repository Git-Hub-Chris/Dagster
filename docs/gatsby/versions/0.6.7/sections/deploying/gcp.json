{
  "parents": [{ "link": "../", "title": "Deploying Dagster" }],
  "prev": { "link": "../aws/", "title": "AWS Deployment" },
  "next": { "link": "../reference/", "title": "Reference" },
  "title": "GCP Deployment",
  "meta": {},
  "body": "<div class=\"section\" id=\"gcp-deployment\">\n<span id=\"deployment-gcp\"></span><h1>GCP Deployment<a class=\"headerlink\" href=\"#gcp-deployment\" title=\"Permalink to this headline\">\u00b6</a></h1>\n<p class=\"rubric\">Compute Engine hosted Dagit</p>\n<p>To host dagit on a bare VM or in Docker on ECS, see the <a class=\"reference external\" href=\"local.html\">Local or Standalone Dagit</a>\nguide.</p>\n<p class=\"rubric\">Execution</p>\n<p>Out of the box, Dagster runs single-process execution. To enable multi-process execution, add the\nfollowing to your pipeline configuration YAML:</p>\n<div class=\"literal-block-wrapper docutils container\" id=\"id1\">\n<div class=\"code-block-caption\"><span class=\"caption-text\">execution_config.yaml</span><a class=\"headerlink\" href=\"#id1\" title=\"Permalink to this code\">\u00b6</a></div>\n<div class=\"highlight-yaml notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"nt\">execution</span><span class=\"p\">:</span>\n  <span class=\"nt\">multiprocess</span><span class=\"p\">:</span>\n    <span class=\"nt\">max_concurrent</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">0</span>\n<span class=\"nt\">storage</span><span class=\"p\">:</span>\n  <span class=\"nt\">filesystem</span><span class=\"p\">:</span>\n</pre></div>\n</div>\n</div>\n<p class=\"rubric\">Run / Events Storage</p>\n<p>We recommend launching a Cloud SQL PostgreSQL instance for run and events data. You should then\nconfigure Dagit to use Cloud SQL; as noted previously, this can be accomplished by adding the\nfollowing to <code class=\"docutils literal notranslate\"><span class=\"pre\">$DAGSTER_HOME/dagster.yaml</span></code>:</p>\n<div class=\"literal-block-wrapper docutils container\" id=\"id2\">\n<div class=\"code-block-caption\"><span class=\"caption-text\">dagster.yaml</span><a class=\"headerlink\" href=\"#id2\" title=\"Permalink to this code\">\u00b6</a></div>\n<div class=\"highlight-yaml notranslate\"><div class=\"highlight\"><pre><span></span> <span class=\"nt\">run_storage</span><span class=\"p\">:</span>\n     <span class=\"nt\">module</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">dagster_postgres.run_storage</span>\n     <span class=\"nt\">class</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">PostgresRunStorage</span>\n     <span class=\"nt\">config</span><span class=\"p\">:</span>\n         <span class=\"nt\">postgres_url</span><span class=\"p\">:</span> <span class=\"s\">&quot;postgresql://{username}:{password}@{host}:5432/{database}&quot;</span>\n\n <span class=\"nt\">event_log_storage</span><span class=\"p\">:</span>\n     <span class=\"nt\">module</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">dagster_postgres.event_log</span>\n     <span class=\"nt\">class</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">PostgresEventLogStorage</span>\n     <span class=\"nt\">config</span><span class=\"p\">:</span>\n         <span class=\"nt\">postgres_url</span><span class=\"p\">:</span> <span class=\"s\">&quot;postgresql://{username}:{password}@{host}:5432/{database}&quot;</span>\n</pre></div>\n</div>\n</div>\n<p>In this case, you\u2019ll want to ensure you provide the right connection strings for your Cloud SQL\ninstance, and that the node or container hosting Dagit is able to connect to RDS.</p>\n<p class=\"rubric\">GCS Intermediates Storage</p>\n<p>You\u2019ll also want to configure a GCS bucket to use for Dagster intermediates (see the <a class=\"reference external\" href=\"../tutorial/intermediates.html\">intermediates\ntutorial guide</a> for more info). Dagster supports serializing data\npassed between solids to GCS; to enable this, you need to add S3 storage to your\n<code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">ModeDefinition</span></code>:</p>\n<p>Then, just add the following YAML to your pipeline config:</p>\n<div class=\"literal-block-wrapper docutils container\" id=\"id3\">\n<div class=\"code-block-caption\"><span class=\"caption-text\">execution_config.yaml</span><a class=\"headerlink\" href=\"#id3\" title=\"Permalink to this code\">\u00b6</a></div>\n<div class=\"highlight-yaml notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"nt\">storage</span><span class=\"p\">:</span>\n  <span class=\"nt\">gcs</span><span class=\"p\">:</span>\n    <span class=\"nt\">config</span><span class=\"p\">:</span>\n      <span class=\"nt\">gcs_bucket</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">your-s3-bucket-name</span>\n</pre></div>\n</div>\n</div>\n<p>With this in place, your pipeline runs will store intermediates on GCS in the location\n<code class=\"docutils literal notranslate\"><span class=\"pre\">gs://&lt;bucket&gt;/dagster/storage/&lt;pipeline</span> <span class=\"pre\">run</span> <span class=\"pre\">id&gt;/intermediates/&lt;solid</span> <span class=\"pre\">name&gt;.compute</span></code></p>\n</div>\n",
  "metatags": "",
  "rellinks": [
    ["genindex", "General Index", "I", "index"],
    ["py-modindex", "Python Module Index", "", "modules"],
    ["sections/deploying/reference", "Reference", "N", "next"],
    ["sections/deploying/aws", "AWS Deployment", "P", "previous"]
  ],
  "sourcename": "sections/deploying/gcp.rst.txt",
  "toc": "<ul>\n<li><a class=\"reference internal\" href=\"#\">GCP Deployment</a></li>\n</ul>\n",
  "display_toc": false,
  "page_source_suffix": ".rst",
  "current_page_name": "sections/deploying/gcp",
  "sidebars": ["globaltoc.html", "searchbox.html"],
  "customsidebar": null,
  "alabaster_version": "0.7.12"
}
