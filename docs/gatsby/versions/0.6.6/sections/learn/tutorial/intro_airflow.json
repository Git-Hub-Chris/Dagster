{
  "parents": [
    { "link": "../../learn/", "title": "Learn" },
    { "link": "../", "title": "Tutorial" }
  ],
  "prev": { "link": "../scheduler/", "title": "Scheduling pipeline runs" },
  "next": { "link": "../../airline_demo/", "title": "Airline Demo" },
  "title": "Deploying to Airflow",
  "meta": {},
  "body": "<div class=\"section\" id=\"deploying-to-airflow\">\n<h1>Deploying to Airflow<a class=\"headerlink\" href=\"#deploying-to-airflow\" title=\"Permalink to this headline\">\u00b6</a></h1>\n<p>Although Dagster includes stand-alone functionality for\n<a class=\"reference internal\" href=\"../hello_cereal/#executing-our-first-pipeline\"><span class=\"std std-ref\">executing</span></a>, <a class=\"reference internal\" href=\"../scheduler/#scheduler\"><span class=\"std std-ref\">scheduling</span></a>, and\n<a class=\"reference internal\" href=\"../../../deploying/dagit/#standalone-dagit\"><span class=\"std std-ref\">deploying pipelines on AWS</span></a>, we also support an incremental adoption\npath on top of existing <a class=\"reference external\" href=\"https://airflow.apache.org/\">Apache Airflow</a> installs.</p>\n<p>We\u2019ve seen how Dagster compiles a logical pipeline definition, appropriately parameterized by config,\ninto a concrete execution plan for Dagster\u2019s execution engines. Dagster pipelines can also be\ncompiled into the DAG format used by Airflow \u2013 or, in principle, to any other intermediate\nrepresentation used by a third-party scheduling or orchestration engine.</p>\n<p>Let\u2019s see how to get our simple cereal pipeline to run on Airflow every morning before breakfast,\nat 6:45 AM.</p>\n<div class=\"section\" id=\"requirements\">\n<h2>Requirements<a class=\"headerlink\" href=\"#requirements\" title=\"Permalink to this headline\">\u00b6</a></h2>\n<p>You\u2019ll need an existing Airflow installation, and to install the <code class=\"docutils literal notranslate\"><span class=\"pre\">dagster-airflow</span></code> library into\nthe Python environments in which your Airflow webserver and worker run:</p>\n<div class=\"highlight-shell notranslate\"><div class=\"highlight\"><pre><span></span>$ pip install dagster-airflow\n</pre></div>\n</div>\n<p>You\u2019ll also need to make sure that the Dagster pipeline you want to run using Airflow is available\nin the Python environments in which your Airflow webserver and worker run.</p>\n</div>\n<div class=\"section\" id=\"scaffolding-your-pipeline-for-airflow\">\n<h2>Scaffolding your pipeline for Airflow<a class=\"headerlink\" href=\"#scaffolding-your-pipeline-for-airflow\" title=\"Permalink to this headline\">\u00b6</a></h2>\n<p>We\u2019ll use our familiar, simple demo pipeline:</p>\n<div class=\"literal-block-wrapper docutils container\" id=\"id1\">\n<div class=\"code-block-caption\"><span class=\"caption-text\">airflow.py</span><a class=\"headerlink\" href=\"#id1\" title=\"Permalink to this code\">\u00b6</a></div>\n<div class=\"highlight-default notranslate\"><table class=\"highlighttable\"><tr><td class=\"linenos\"><div class=\"linenodiv\"><pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21</pre></div></td><td class=\"code\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">csv</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">dagster</span> <span class=\"kn\">import</span> <span class=\"n\">pipeline</span><span class=\"p\">,</span> <span class=\"n\">solid</span>\n<span class=\"kn\">from</span> <span class=\"nn\">dagster.utils</span> <span class=\"kn\">import</span> <span class=\"n\">file_relative_path</span>\n\n\n<span class=\"nd\">@solid</span>\n<span class=\"k\">def</span> <span class=\"nf\">hello_cereal</span><span class=\"p\">(</span><span class=\"n\">context</span><span class=\"p\">):</span>\n    <span class=\"n\">dataset_path</span> <span class=\"o\">=</span> <span class=\"n\">file_relative_path</span><span class=\"p\">(</span><span class=\"vm\">__file__</span><span class=\"p\">,</span> <span class=\"s2\">&quot;cereal.csv&quot;</span><span class=\"p\">)</span>\n    <span class=\"n\">context</span><span class=\"o\">.</span><span class=\"n\">log</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"n\">dataset_path</span><span class=\"p\">)</span>\n    <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">dataset_path</span><span class=\"p\">,</span> <span class=\"s1\">&#39;r&#39;</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">fd</span><span class=\"p\">:</span>\n        <span class=\"n\">cereals</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">row</span> <span class=\"k\">for</span> <span class=\"n\">row</span> <span class=\"ow\">in</span> <span class=\"n\">csv</span><span class=\"o\">.</span><span class=\"n\">DictReader</span><span class=\"p\">(</span><span class=\"n\">fd</span><span class=\"p\">)]</span>\n\n    <span class=\"n\">context</span><span class=\"o\">.</span><span class=\"n\">log</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span>\n        <span class=\"s1\">&#39;Found </span><span class=\"si\">{n_cereals}</span><span class=\"s1\"> cereals&#39;</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">n_cereals</span><span class=\"o\">=</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">cereals</span><span class=\"p\">))</span>\n    <span class=\"p\">)</span>\n\n\n<span class=\"nd\">@pipeline</span>\n<span class=\"k\">def</span> <span class=\"nf\">hello_cereal_pipeline</span><span class=\"p\">():</span>\n    <span class=\"n\">hello_cereal</span><span class=\"p\">()</span>\n</pre></div>\n</td></tr></table></div>\n</div>\n<p>To compile this existing pipeline to Airflow, we\u2019ll use the <code class=\"docutils literal notranslate\"><span class=\"pre\">dagster-airflow</span></code> CLI tool. By\ndefault, this tool will write the Airflow-compatible DAG scaffold out to <code class=\"docutils literal notranslate\"><span class=\"pre\">$AIRFLOW_HOME/dags</span></code>.</p>\n<div class=\"highlight-shell notranslate\"><div class=\"highlight\"><pre><span></span>$ dagster-airflow scaffold <span class=\"se\">\\</span>\n    --module-name dagster_examples.intro_tutorial.airflow <span class=\"se\">\\</span>\n    --pipeline-name hello_cereal_pipeline\nWrote DAG scaffold to file: <span class=\"nv\">$AIRFLOW_HOME</span>/dags/hello_cereal_pipeline.py\n</pre></div>\n</div>\n<p>Let\u2019s take a look at the generated file:</p>\n<div class=\"literal-block-wrapper docutils container\" id=\"id2\">\n<div class=\"code-block-caption\"><span class=\"caption-text\">hello_cereal_pipeline.py</span><a class=\"headerlink\" href=\"#id2\" title=\"Permalink to this code\">\u00b6</a></div>\n<div class=\"highlight-default notranslate\"><table class=\"highlighttable\"><tr><td class=\"linenos\"><div class=\"linenodiv\"><pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48</pre></div></td><td class=\"code\"><div class=\"highlight\"><pre><span></span><span class=\"sd\">&#39;&#39;&#39;</span>\n<span class=\"sd\">The airflow DAG scaffold for dagster_examples.intro_tutorial.airflow.hello_cereal_pipeline</span>\n\n<span class=\"sd\">Note that this docstring must contain the strings &quot;airflow&quot; and &quot;DAG&quot; for</span>\n<span class=\"sd\">Airflow to properly detect it as a DAG</span>\n<span class=\"sd\">See: http://bit.ly/307VMum</span>\n<span class=\"sd\">&#39;&#39;&#39;</span>\n<span class=\"kn\">import</span> <span class=\"nn\">datetime</span>\n\n<span class=\"kn\">import</span> <span class=\"nn\">yaml</span>\n<span class=\"kn\">from</span> <span class=\"nn\">dagster_airflow.factory</span> <span class=\"kn\">import</span> <span class=\"n\">make_airflow_dag</span>\n\n<span class=\"c1\">################################################################################</span>\n<span class=\"c1\"># #</span>\n<span class=\"c1\"># # This environment is auto-generated from your configs and/or presets</span>\n<span class=\"c1\"># #</span>\n<span class=\"c1\">################################################################################</span>\n<span class=\"n\">ENVIRONMENT</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;&#39;&#39;</span>\n<span class=\"s1\">storage:</span>\n<span class=\"s1\">  filesystem:</span>\n<span class=\"s1\">    config:</span>\n<span class=\"s1\">      base_dir: /tmp/dagster-airflow/hello_cereal_pipeline</span>\n\n<span class=\"s1\">&#39;&#39;&#39;</span>\n\n\n<span class=\"c1\">################################################################################</span>\n<span class=\"c1\"># #</span>\n<span class=\"c1\"># # NOTE: these arguments should be edited for your environment</span>\n<span class=\"c1\"># #</span>\n<span class=\"c1\">################################################################################</span>\n<span class=\"n\">DEFAULT_ARGS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">&#39;owner&#39;</span><span class=\"p\">:</span> <span class=\"s1\">&#39;airflow&#39;</span><span class=\"p\">,</span>\n    <span class=\"s1\">&#39;depends_on_past&#39;</span><span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">,</span>\n    <span class=\"s1\">&#39;start_date&#39;</span><span class=\"p\">:</span> <span class=\"n\">datetime</span><span class=\"o\">.</span><span class=\"n\">datetime</span><span class=\"p\">(</span><span class=\"mi\">2019</span><span class=\"p\">,</span> <span class=\"mi\">11</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">),</span>\n    <span class=\"s1\">&#39;email&#39;</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">&#39;airflow@example.com&#39;</span><span class=\"p\">],</span>\n    <span class=\"s1\">&#39;email_on_failure&#39;</span><span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">,</span>\n    <span class=\"s1\">&#39;email_on_retry&#39;</span><span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n\n<span class=\"n\">dag</span><span class=\"p\">,</span> <span class=\"n\">tasks</span> <span class=\"o\">=</span> <span class=\"n\">make_airflow_dag</span><span class=\"p\">(</span>\n    <span class=\"c1\"># NOTE: you must ensure that dagster_examples.intro_tutorial.airflow is</span>\n    <span class=\"c1\"># installed or available on sys.path, otherwise, this import will fail.</span>\n    <span class=\"n\">module_name</span><span class=\"o\">=</span><span class=\"s1\">&#39;dagster_examples.intro_tutorial.airflow&#39;</span><span class=\"p\">,</span>\n    <span class=\"n\">pipeline_name</span><span class=\"o\">=</span><span class=\"s1\">&#39;hello_cereal_pipeline&#39;</span><span class=\"p\">,</span>\n    <span class=\"n\">environment_dict</span><span class=\"o\">=</span><span class=\"n\">yaml</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">ENVIRONMENT</span><span class=\"p\">),</span>\n    <span class=\"n\">dag_kwargs</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">&#39;default_args&#39;</span><span class=\"p\">:</span> <span class=\"n\">DEFAULT_ARGS</span><span class=\"p\">,</span> <span class=\"s1\">&#39;max_active_runs&#39;</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">},</span>\n<span class=\"p\">)</span>\n</pre></div>\n</td></tr></table></div>\n</div>\n<p>This is a fairly straightforward file with four parts.</p>\n<p>First, we import the basic prerequisites to define our DAG (and also make sure that the string\n\u201cDAG\u201d appears in the file, so that the Airflow webserver will detect it).</p>\n<p>Second, we define the config that Dagster will compile our pipeline against. Unlike Dagster\npipelines, Airflow DAGs can\u2019t be parameterized dynamically at execution time, so this config is\nstatic after it\u2019s loaded by the Airflow webserver.</p>\n<p>Third, we set the <code class=\"docutils literal notranslate\"><span class=\"pre\">DEFAULT_ARGS</span></code> that will be passed down as the <code class=\"docutils literal notranslate\"><span class=\"pre\">default_args</span></code> argument to the\n<code class=\"docutils literal notranslate\"><span class=\"pre\">airflow.DAG</span></code> <a class=\"reference external\" href=\"https://airflow.apache.org/tutorial.html#example-pipeline-definition\">constructor</a>.</p>\n<p>Finally, we define the DAG and its constituent tasks using\n<a class=\"reference internal\" href=\"../../../api/apidocs/dagster_airflow/#dagster_airflow.make_airflow_dag\" title=\"dagster_airflow.make_airflow_dag\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">make_airflow_dag</span></code></a>. If you run this code interactively,\nyou\u2019ll see that <code class=\"docutils literal notranslate\"><span class=\"pre\">dag</span></code> and <code class=\"docutils literal notranslate\"><span class=\"pre\">tasks</span></code> are ordinary Airflow objects, just as you\u2019d expect to see\nwhen defining an Airflow pipeline manually:</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">dag</span>\n<span class=\"go\">&lt;DAG: hello_cereal_pipeline&gt;</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">tasks</span>\n<span class=\"go\">[&lt;Task(DagsterPythonOperator): hello_cereal&gt;]</span>\n</pre></div>\n</div>\n</div>\n<div class=\"section\" id=\"running-a-pipeline-on-airflow\">\n<h2>Running a pipeline on Airflow<a class=\"headerlink\" href=\"#running-a-pipeline-on-airflow\" title=\"Permalink to this headline\">\u00b6</a></h2>\n<p>Ensure that the Airflow webserver, scheduler (and any workers appropriate to the executor you have\nconfigured) are running. The <code class=\"docutils literal notranslate\"><span class=\"pre\">dagster-airflow</span></code> CLI tool will automatically put the generated DAG\ndefinition in <code class=\"docutils literal notranslate\"><span class=\"pre\">$AIRLFLOW_HOME/dags</span></code>, but if you have a different setup, you should make sure that\nthis file is wherever the Airflow webserver looks for DAG definitions.</p>\n<p>When you fire up the Airflow UI, you should see the new DAG:</p>\n<a class=\"\"\n               data-lightbox=\"group-dfe98e78-0f79-4ea9-908a-c301123276db\"\n               href=\"../../../../_images/intro_airflow_one1.png\"\n               title=\"\"\n               data-title=\"\"\n               ><img src=\"../../../../_images/intro_airflow_one1.png\"\n                     class=\"\"\n                     width=\"100%\"\n                     height=\"auto\"\n                     alt=\"\"/>\n                </a><p>Kick off a run manually, and you\u2019ll be able to use the ordinary views of the pipeline\u2019s progress:</p>\n<a class=\"\"\n               data-lightbox=\"group-b9bac13c-0de2-432a-b053-2062bc091919\"\n               href=\"../../../../_images/intro_airflow_dag_view1.png\"\n               title=\"\"\n               data-title=\"\"\n               ><img src=\"../../../../_images/intro_airflow_dag_view1.png\"\n                     class=\"\"\n                     width=\"100%\"\n                     height=\"auto\"\n                     alt=\"\"/>\n                </a><p>And logs will be available in the Airflow log viewer:</p>\n<a class=\"\"\n               data-lightbox=\"group-3a2cfd40-4a6e-4217-aff2-cb13a871c80d\"\n               href=\"../../../../_images/intro_airflow_logs_view1.png\"\n               title=\"\"\n               data-title=\"\"\n               ><img src=\"../../../../_images/intro_airflow_logs_view1.png\"\n                     class=\"\"\n                     width=\"100%\"\n                     height=\"auto\"\n                     alt=\"\"/>\n                </a></div>\n<div class=\"section\" id=\"more-sophisticated-setups\">\n<h2>More sophisticated setups<a class=\"headerlink\" href=\"#more-sophisticated-setups\" title=\"Permalink to this headline\">\u00b6</a></h2>\n<p>This approach requires that Dagster, all of the Python requirements of your Dagster pipelines, and\nyour Dagaster pipelines themselves be importable in the environment in which your Airflow tasks\noperate, because under the hood it uses Airflow\u2019s <code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">PythonOperator</span></code> to define\ntasks.</p>\n<p><code class=\"docutils literal notranslate\"><span class=\"pre\">dagster-airflow</span></code> also includes facilities for compiling Dagster pipelines to Airflow DAGs whose\ntasks use the <a class=\"reference external\" href=\"https://airflow.apache.org/_api/airflow/operators/docker_operator/index.html#airflow.operators.docker_operator.DockerOperator\" title=\"(in Airflow v1.10.6)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">DockerOperator</span></code></a> or\n<a class=\"reference external\" href=\"https://airflow.apache.org/_api/airflow/contrib/operators/kubernetes_pod_operator/index.html#airflow.contrib.operators.kubernetes_pod_operator.KubernetesPodOperator\" title=\"(in Airflow v1.10.6)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">KubernetesPodOperator</span></code></a>.\nFor details, see the <a class=\"reference internal\" href=\"../../../deploying/airflow/#airflow\"><span class=\"std std-ref\">deployment guide for Airflow</span></a>.</p>\n</div>\n</div>\n",
  "metatags": "",
  "rellinks": [
    ["genindex", "General Index", "I", "index"],
    ["py-modindex", "Python Module Index", "", "modules"],
    ["sections/learn/airline_demo", "Airline Demo", "N", "next"],
    [
      "sections/learn/tutorial/scheduler",
      "Scheduling pipeline runs",
      "P",
      "previous"
    ]
  ],
  "sourcename": "sections/learn/tutorial/intro_airflow.rst.txt",
  "toc": "<ul>\n<li><a class=\"reference internal\" href=\"#\">Deploying to Airflow</a><ul>\n<li><a class=\"reference internal\" href=\"#requirements\">Requirements</a></li>\n<li><a class=\"reference internal\" href=\"#scaffolding-your-pipeline-for-airflow\">Scaffolding your pipeline for Airflow</a></li>\n<li><a class=\"reference internal\" href=\"#running-a-pipeline-on-airflow\">Running a pipeline on Airflow</a></li>\n<li><a class=\"reference internal\" href=\"#more-sophisticated-setups\">More sophisticated setups</a></li>\n</ul>\n</li>\n</ul>\n",
  "display_toc": true,
  "page_source_suffix": ".rst",
  "current_page_name": "sections/learn/tutorial/intro_airflow",
  "sidebars": ["globaltoc.html", "searchbox.html"],
  "customsidebar": null,
  "alabaster_version": "0.7.12"
}
