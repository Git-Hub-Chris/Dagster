{
  "parents": [{ "link": "../learn/", "title": "Learn" }],
  "prev": { "link": "../airline_demo/", "title": "Airline Demo" },
  "next": { "link": "../guides/", "title": "Guides" },
  "title": "Principles",
  "meta": {},
  "body": "<div class=\"section\" id=\"principles\">\n<h1>Principles<a class=\"headerlink\" href=\"#principles\" title=\"Permalink to this headline\">\u00b6</a></h1>\n<p>Dagster is opinionated about how data pipelines should be built and structured. What do we think\nis important?</p>\n<p class=\"rubric\">Functional</p>\n<p>Data pipelines should be expressed as DAGs (directed acyclic graphs) of functional, idempotent\ncomputations. Individual nodes in the graph consume their inputs, perform some computation, and\nyield outputs, either with no side effects or with clearly advertised side effects. Given the\nsame inputs and configuration, the computation should always produce the same output. If these\ncomputations have external dependencies, these should be parametrizable, so that the computations\nmay execute in different environments.</p>\n<blockquote>\n<div><ul class=\"simple\">\n<li><p>See Maxime Beauchemin\u2019s Medium article on <a class=\"reference external\" href=\"https://bit.ly/2LxDgnr\">Functional Data Engineering</a>\nfor an excellent overview of functional programing in batch computations.</p></li>\n</ul>\n</div></blockquote>\n<p class=\"rubric\">Self-describing</p>\n<p>Data pipelines should be self-describing, with rich metadata and types. Users should be able to\napproach an unfamiliar pipeline and use tooling to inspect it and discover its structure,\ncapabilities, and requirements. Pipeline metadata should be co-located with the pipeline\u2019s actual\ncode: documentation and code should be delivered as a single artifact.</p>\n<p class=\"rubric\">Compute-agnostic</p>\n<p>Heterogeneity in data pipelines is the norm, rather than the exception. Data pipelines are written\ncollaboratively by many people in different personas \u2013 data engineers, machine-learning engineers,\ndata scientists, analysts and so on \u2013 who have different needs and tools, and are particular about\nthose tools.</p>\n<p>Dagster has opinions about best practices for structuring data pipelines. It has no opinions\nabout what libraries and engines should do actual compute. Dagster pipelines can be made up of\nany Python computations, whether they use Pandas, Spark, or call out to SQL or any other DSL or\nlibrary deemed appropriate to the task.</p>\n<p class=\"rubric\">Testable</p>\n<p>Testing data pipelines is notoriously difficult. Because testing is so difficult, it is often never\ndone, or done poorly. Dagster pipelines are designed to be tested. Dagster provides explicit support\nfor pipeline authors to manage and maintain multiple execution environments \u2013 for example, unit\ntesting, integration testing, and production environments. Dagster can also execute arbitrary\nsubsets and nodes of pipelines, which is critical for testability (and useful in operational\ncontexts as well).</p>\n<p class=\"rubric\">Verifiable data quality</p>\n<p>Testing code is important in data pipelines, but it is not sufficient. Data quality tests \u2013 run\nduring every meaningful stage of computation in production \u2013 are critical to reduce the\nmaintenance burden of data pipelines. Pipeline authors generally do not have control over their\ninput data, and make many implicit assumptions about that data. Data formats can also change\nover time. In order to control this entropy, Dagster encourages users to computationally verify\nassumptions (known as expectations) about the data as part of the pipeline process. This way, when\nthose assumptions break, the breakage can be reported quickly, easily, and with rich metadata\nand diagnostic information. These expectations can also serve as contracts between teams.</p>\n<blockquote>\n<div><ul class=\"simple\">\n<li><p>See <a class=\"reference external\" href=\"https://bit.ly/2mxDS1R\">Down with Pipeline Debt!</a> for a primer on pipeline tests for\ndata quality.</p></li>\n</ul>\n</div></blockquote>\n<p class=\"rubric\">Gradual, optional typing</p>\n<p>Dagster contains a type system to describe the values flowing through the pipeline and the\nconfiguration of the pipeline. As pipelines mature, gradual typing lets nodes in a pipeline\nknow if they are properly arranged and configured prior to execution, and provides rich\ndocumentation and runtime error checking.</p>\n</div>\n",
  "metatags": "",
  "rellinks": [
    ["genindex", "General Index", "I", "index"],
    ["py-modindex", "Python Module Index", "", "modules"],
    ["sections/learn/guides/index", "Guides", "N", "next"],
    ["sections/learn/airline_demo", "Airline Demo", "P", "previous"]
  ],
  "sourcename": "sections/learn/principles.rst.txt",
  "toc": "<ul>\n<li><a class=\"reference internal\" href=\"#\">Principles</a></li>\n</ul>\n",
  "display_toc": false,
  "page_source_suffix": ".rst",
  "current_page_name": "sections/learn/principles",
  "sidebars": ["globaltoc.html", "searchbox.html"],
  "customsidebar": null,
  "alabaster_version": "0.7.12"
}
